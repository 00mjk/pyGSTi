	<h1>Summary</h1>
	<!-- (goSwitchboard1)s -->
<p>Welcome to a pyGSTi analysis report!  This report is organized into <q>tabs</q>, each of which is accessible from the sidebar on the left.  This Summary tab summarizes the most popular analyses and figures of merit.  Much more detailed analysis is available on other tabs.  If this report encapsulates multiple datasets, estimates, or gauges, then you can switch between those using the dropdown menus on the sidebar.  Clicking on the bold <b>Table X</b> or <b>Figure X</b> caption titles expands the full caption text describing what each table or plot is in more detail.</p>

	<figure id="progressBarPlot_sum" class='tbl'>
	  <figcaption><span class="captiontitle">Model violation summary.</span> <span class="captiondetail">This figure is about goodness-of-fit.  This plot shows how well (or badly) this estimate fits the data.    PyGSTi finds the maximum value of the loglikelihood (<span class="math">-2\log\mathrm{Pr(data|gateset)}</span>), and compares it to what we expect to see <i>if</i> the data were generated by a Markovian gateset.  In this plot, each bar shows by how many standard deviations the <i>actual</i> log-likelihood exceeds its expected value.  Expected values and standard deviations are derived from <span class="math">\chi^2</span> theory.  On the horizontal axis, <span class="math">L</span> indexes different ML estimates based on datasets including only circuits of length up to <span class="math">L</span>.  Low values indicate better fits (less model violation).  Each bar is colored according to the <q>star</q> rating shown in the Model Violation tab.</span></figcaption>
	  %(progressBarPlot_sum)s
	</figure>

	<figure id="bestEstimateColorHistogram" class='tbl'>
	  <figcaption><span class="captiontitle">Histogram of per-circuit model violation.</span> <span class="captiondetail">This figure is about goodness-of-fit.  When the estimate doesn't fit the data perfectly, we can quantify how well it fails to predict each individual circuit in the dataset, using the loglikelihood (<span class="math">-2\log\mathrm{Pr(data|gateset)}</span>).  This plot shows a histogram of the those values for all the circuits in the dataset.  Ideally, they should have a <span class="math">\chi^2</span> distribution.  Red indicates data that are inconsistent with the model at the 0.95 confidence level, as shown in more detail in the Model Violation tab.</span> </figcaption>
	  %(bestEstimateColorHistogram)s
	</figure>

	<figure id="bestGatesVsTargetTable_sum" class='tbl'>
	  <figcaption><span class="captiontitle">Comparison of estimated gates to targets.</span> <span class="captiondetail">This table is about gate error metrics (fidelity). The metrics in this table compare the estimated gates to their ideal counterparts, and can generally be interpreted as some kind of error rate (per gate use).  Entanglement (process) fidelity and 1/2-diamond norm are the best known of these; they are the same for purely stochastic errors, but coherent errors contribute much more to diamond norm.  1/2-trace-distance is a proxy for diamond norm that doesn't require cvxPy to be installed.  The Eigenvalue metrics are gauge-invariant versions of fidelity and diamond-norm that only depend on the gate itself (not its relationship to other gates).  Hovering the pointer over a heading will pop up a description.</span></figcaption>
	  %(bestGatesVsTargetTable_sum)s
	</figure>

