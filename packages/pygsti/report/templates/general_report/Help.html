<h1>How to use this report</h1>
<p>Welcome to a pyGSTi report! This HTML document provides an interactive view onto a lot of information about one or more gateset tomography (GST) experiments that were analyzed using the pyGSTi software. This <q>Help</q> tab should help you use this report’s interactive features, figure out where to find things, and access the context-sensitive help features embedded throughout the report.</p>


<h2>Background</h2>
<p>PyGSTi’s primary purpose is to ingest GST datasets and find a good estimate of the gateset that generated that data. But pyGSTi can also produce a lot of detailed analyses and visualizations of the estimates that it generates. That’s what you’ll find in this report. You can inspect the raw estimated gateset too, but if you want to do your own calculations with it — e.g., to simulate circuits or calculate interesting quantities that the pyGSTi authors haven’t thought of — then the best way to do that is by using pyGSTi itself in a Jupyter or iPython notebook.</p>


<h2>This report’s structure</h2>
<p>PyGSTi uses HTML for reporting because it’s pretty portable and supports interactivity. Interactivity makes it possible to embed a lot of different perspectives and analyses, while not overwhelming you with too much information at once or requiring you to scroll through long static (e.g. PDF) documents. In this report, actual content is displayed in the main panel, while navigation tools that let you decide what content to examine are collected in a sidebar on the left. The tables and figures in the main panel are also somewhat interactive (see “Interactions with content” below). Most of them dynamically change what they show depending on the positions of one or more <em>switches</em> - dropdown-boxes, button-sets, or sliders.  Most such switches are located on the left sidebar, and some are located beneath the one or two plots that depend on them.  Note that some content is generated on the fly, so there may be a lag the very first time you view a given tab, while your browser makes plots or renders math formula.</p>

<h2>Choosing what to see via the sidebar</h2>
<p>The sidebar provides two distinct ways to control what you see. First, the data analysis is broken up into different <b>tabs</b> that are listed on the sidebar, and which you can hop between. Each tab collects a particular category of analysis presented as some set of tables and figures. Second, for reports which contain multiple analyses, the sidebar contains <em>switches</em> which allow you to pick which analysis is displayed in the tables and figures.  A report can contain: (1) multiple distinct datasets; (2) the results of different estimators (each associated with a given dataset); and (3) multiple distinct but equivalent representations (gauges) for each estimate. You can choose between these options using the drop down menus labeled <q>Dataset</q> and <q>Estimate</q>, and the <q>Gauge optimization</q> button group at the bottom of the sidebar. A missing switch means this report doesn’t contain multiple options of that type.</p>


<h2>Interacting with content</h2>
<p>Each tab presents a (hopefully manageable) amount of content arranged into objects — figures and tables — that have some interactive properties. Here are some general tips and rules.
  <ul>
    <li><b>Resizing:</b> Each object can be resized by dragging its lower right corner.</li>
    <li><b>Zooming:</b> You can zoom in on plots’ axes by clicking and dragging within the figure — and double-clicking, or tapping the house icon that pops up in the upper right when the pointer’s over a figure, will reset the axes.</li>
    <li><b>Exporting:</b> Plots can be <b>saved in PNG</b> format by tapping the <b>camera icon</b> (which is only visible when hovering over a plot). <em>User beware:</em> this is a builtin funtionality of the Plotly library, and we find that sometimes the saved PNG does not look like the original plot, especially in aspect ratio.  If the report was constructed with the appropriate options, there will also be links to download both plots and tables a portable document format, Python <q>pickle</q> files, and/or latex (tables only).  Plots will have additional download icons next to the camera icon, and tables will have <b>PDF</b>, <b>PKL</b>, and/or <b>TEX</b> links beneath them.  Plot PKL files contain a pickled dictionary of the plotted data; Table PKL files contain a pickled Pandas DataFrame object.</li>
    <li>Clicking on Table or Figure titles will expand them into a <b>full descriptive caption</b>.</li>
    <li><b>Hovering</b> over a colored bar or box will often reveal a tool tip showing the exact number that bar or box represents.  Hovering over table headings will bring up descriptive text.  In the plots that show per-sequence model violation, hovering over any data point will bring up fairly extensive details about the datum that generated it.</li>
    <li>Finally, if you see the pyGSTi logo, it’s a placeholder for a plot that wasn’t automatically generated; click on it to generate the plot.
  </ul>
</p>

<h2>Quick guide to Datasets, Estimates, and Gauge Optimizations</h2>
<p>The single biggest change from the old PDF report format is the ability to report simultaneously on — and compare — multiple gateset estimates. This report may contain an unlimited number of distinct gatesets. Although they’re often all derived from the same dataset, they may not be. For example, a single report could contain:
  <ol>
    <li> datasets from separate GST experiments on each qubit on a chip;</li>
    <li> datasets from two identical GST experiments done at different times;</li>
    <li> datasets from GST experiments on the same system, but with gate implementations;</li>
    <li> a 2-qubit GST dataset together with 1-qubit GST datasets extracted from it;</li>
    <li> many other possibilities.</li>
  </ol>
  The sidebar’s <q>Dataset</q> dropdown menu (if present) lets you select a dataset. Then, the <q>Estimate</q> dropdown (if present) will list all the different estimates that are available for <em>any of the datasets</em> in the report.  If you choose an estimate that was <em>not</em> generate for the current dataset (but was for another dataset, otherwise it wouldn't be in the list), the plots and figures dependent on that choise will turn into big "NA" labels.  Different estimates are usually generated by different statistical estimators. PyGSTi usually provides maximum likelihood estimates (although others are certainly possible!), but it can do MLE with no constraints at all (<q>Full</q>), or constrained to trace-preserving maps (<q>TP</q>), or constrained to completely positive maps (<q>CPTP</q>).  Some reports include separate <q>*.robust</q> variations of those estimators in which poorly-fit data were deprecated, and some reports include the target gates themselves (<q>Target</q>) as an option.</p>

<p>Finally, in order to analyze each estimated gateset, pyGSTi has to choose a representation — a gauge — for it.  Since pyGSTi does this gauge-fixing internally by defining an objective function and then finding the gauge that optimizes it, the choice-of-representation is referred to as <q>Gauge Optimization</q>.  The sidebar shows in a table beneath the switches a description of the objective function used to generate this gateset.  If the report contains multiple gauge optimizations, you can choose between them by pushing the appropriate button. Choosing a good gauge is hard, and neither pyGSTi nor its users always get it right. If something reported in the <q>Summary</q> or <q>Gauge-dependent error metrics</q> tabs looks startling or implausible, it might be due to a poorly chosen gauge. Try a different gauge-optimization choice, or cross-validate whatever you see against things from the <q>Gauge-invariant error metrics</q> tabs.</p>


<h2>What to look at first (and second)</h2>
<p>If you’re new to pyGSTi reports, this is probably all a bit overwhelming. <em>Don’t panic!</em> There’s a lot of context-sensitive help, and the pyGSTi authors are always happy to answer questions like <q>What does this mean?</q>, or <q>Why would I care about this?</q> But since these reports do contain a lot of stuff, here’s a get-started-quickly guide.</p>

<p>Start with the <q>Summary</q> tab. It will tell you two critical things. First, in Table 3: how close do the gates seem to be to the ideal targets that were specified? Are you doing pretty well, or all messed up for some reason? If whoever did the analysis chose to produce error bars (this can take a lot of computation), they’ll appear in this table. Second, the <q>model violation</q> plots will tell you whether the system seems to be stable and Markovian, or not (in which case, take the metrics in Table 3 with a grain of salt). Don’t forget to flip through the available datasets, estimates, and gauge-optimization choices — or at least the ones you care about — while looking at this tab.</p>

<p>Next, you probably want to know one of two things. Either the GST model was NOT badly violated, in which case you want to know more about the errors in the gates.. or it WAS badly violated, in which case you want to know more about what’s going wrong.</p>

<p>If you want to know more about the errors, start with <q>Gauge Dependent Error Metrics: Overview</q>, then take a quick look at <q>Raw Estimates</q> to confirm that the process matrices look about right, and then spend some quality time with <q>Gate Decompositions</q> and <q>Gate Error Generators</q> if you want to really understand what GST thinks that each individual gate is doing. If at any point you see something weird that might be due to a bad choice of gauge (examples include wildly nonpositive SPAM operations, implausibly high diamond norm errors in gates that you strongly believe to be better than that, and significantly negative elements in the Pauli stochastic part of the error generators), try a different gauge optimization. Or, go to the <q>Gauge-invariant error metrics</q> tabs and try to figure out whether there’s something here that confirms or denies whatever effect is bugging you (e.g., if an estimated gate has an eigenvalue bigger than 1, that will produce crazy negative probabilities, and it’s not a gauge problem).</p>

<p>On the other hand, if there’s a lot of model violation, then you probably want to understand why. The information on the error metrics tabs may or may not be useful — you should be much more cautious about drawing conclusions from them if there’s a lot of model violation. To dig into model violation (aka “non-Markovianity”), start with the <q>Model Violation: Overview</q> tab, which will give you the numbers behind the bar chart from the Summary tab, and also show you whether longer circuits violate the GST model more. (If they do, it’s probably non-Markovianity in the gates. If they don’t, it’s probably something nastier like bistability, slow drift in SPAM operations, or corrupted data). Next, take a deep breath and dig into the “Per-sequence detail” tab, which will show you the (quantitative) inconsistency of every individual circuit with this estimate. Interpreting these charts is a bit of an art, but clusters of red boxes usually indicate that something related to the location of the cluster was suffering drift and/or non-Markovianity.</p>
