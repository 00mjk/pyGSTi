{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using GST to test for context dependence\n",
    "This example shows how to introduce new gate labels into a GST analysis so as to test for context dependence.  In particular, we'll look at the 1-qubit X, Y, I gateset.  Suppose a usual GST analysis cannot fit the model well, and that we think this is due to the fact that a \"Gi\" gate which immediately follows a \"Gx\" gate is affected by some residual noise that isn't otherwise present.  In this case, we can model the system as having two different \"Gi\" gates: \"Gi\" and \"Gi2\", and model the \"Gi\" gate as \"Gi2\" whenever it follows a \"Gx\" gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pygsti\n",
    "from pygsti.construction import std1Q_XYI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll create a mock data set that exhibits this context dependence.  To do this, we add an additional \"Gi2\" gate to the data-generating gate set, generate some data using \"Gi2\"-containing gate sequences, and finally replace all instances of \"Gi2\" with \"Gi\" so that it looks like data that was supposed to have just a single \"Gi\" gate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The usual setup: identify the target gateset, fiducials, germs, and max-lengths\n",
    "gs_target = std1Q_XYI.gs_target\n",
    "fiducials = std1Q_XYI.fiducials\n",
    "germs = std1Q_XYI.germs\n",
    "maxLengths = [1,2,4,8,16,32]\n",
    "\n",
    "# Create a GateSet to generate the data - one that has two identity gates: Gi and Gi2\n",
    "gs_datagen = gs_target.depolarize(gate_noise=0.1, spam_noise=0.001)\n",
    "gs_datagen[\"Gi2\"] = gs_datagen[\"Gi\"].copy()\n",
    "gs_datagen[\"Gi2\"].depolarize(0.1) # depolarize Gi2 even further\n",
    "gs_datagen[\"Gi2\"].rotate( (0,0,0.1), gs_datagen.basis) # and rotate it slightly about the Z-axis\n",
    "\n",
    "# Create a set of gate sequences by constructing the usual set of experiments and using \n",
    "# \"manipulate_gatestring_list\" to replace Gi with Gi2 whenever it follows Gx.  Create a \n",
    "# DataSet using the resulting Gi2-containing list of sequences.\n",
    "listOfExperiments = pygsti.construction.make_lsgst_experiment_list(gs_target, fiducials, fiducials, germs, maxLengths)\n",
    "rules = [ ((\"Gx\",\"Gi\") , (\"Gx\",\"Gi2\")) ] # a single replacement rule: GxGi => GxGi2 \n",
    "listOfExperiments = pygsti.construction.manipulate_gatestring_list(listOfExperiments, rules)\n",
    "ds = pygsti.construction.generate_fake_data(gs_datagen, listOfExperiments, nSamples=10000,\n",
    "                                            sampleError=\"binomial\", seed=1234)\n",
    "\n",
    "# Revert all the Gi2 labels back to Gi, so that the DataSet doesn't contain any Gi2 labels.\n",
    "rev_rules = [ ((\"Gi2\",) , (\"Gi\",)) ] # returns all Gi2's to Gi's \n",
    "ds.process_gate_strings(lambda gstr: pygsti.construction.manipulate_gatestring(gstr,rev_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running \"standard\" GST on this `DataSet` resulst in a bad fit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gate Sequence Creation ---\n",
      " 1585 sequences created\n",
      " Dataset has 1585 entries: 1585 utilized, 0 requested sequences were missing\n",
      "--- LGST ---\n",
      "  Singular values of I_tilde (truncating to first 4 of 6) = \n",
      "  4.2440859008\n",
      "  1.16716001352\n",
      "  0.957280141699\n",
      "  0.94502768798\n",
      "  0.0226509425162\n",
      "  0.00873060801312\n",
      "  \n",
      "  Singular values of target I_tilde (truncating to first 4 of 6) = \n",
      "  4.24264068712\n",
      "  1.41421356237\n",
      "  1.41421356237\n",
      "  1.41421356237\n",
      "  3.03015102482e-16\n",
      "  7.09307430818e-17\n",
      "  \n",
      "--- Iterative MLGST: Iter 1 of 6  92 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "  Sum of Chi^2 = 115.436 (92 data params - 31 model params = expected mean of 61; p-value = 3.20263e-05)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 115.196\n",
      "  Iteration 1 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 2 of 6  168 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "  Sum of Chi^2 = 336.895 (168 data params - 31 model params = expected mean of 137; p-value = 0)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 335.199\n",
      "  Iteration 2 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 3 of 6  441 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "  Sum of Chi^2 = 1661.98 (441 data params - 31 model params = expected mean of 410; p-value = 0)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 1651.09\n",
      "  Iteration 3 took 0.2s\n",
      "  \n",
      "--- Iterative MLGST: Iter 4 of 6  817 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "  Sum of Chi^2 = 3555.55 (817 data params - 31 model params = expected mean of 786; p-value = 0)\n",
      "  Completed in 0.2s\n",
      "  2*Delta(log(L)) = 3536.21\n",
      "  Iteration 4 took 0.3s\n",
      "  \n",
      "--- Iterative MLGST: Iter 5 of 6  1201 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "  Sum of Chi^2 = 4770.26 (1201 data params - 31 model params = expected mean of 1170; p-value = 0)\n",
      "  Completed in 0.3s\n",
      "  2*Delta(log(L)) = 4749.77\n",
      "  Iteration 5 took 0.4s\n",
      "  \n",
      "--- Iterative MLGST: Iter 6 of 6  1585 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "  Sum of Chi^2 = 5259.73 (1585 data params - 31 model params = expected mean of 1554; p-value = 0)\n",
      "  Completed in 0.3s\n",
      "  2*Delta(log(L)) = 5239.66\n",
      "  Iteration 6 took 0.5s\n",
      "  \n",
      "  Switching to ML objective (last iteration)\n",
      "  --- MLGST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "    Maximum log(L) = 2619.48 below upper bound of -2.65382e+07\n",
      "      2*Delta(log(L)) = 5238.95 (1585 data params - 31 model params = expected mean of 1554; p-value = 0)\n",
      "    Completed in 0.3s\n",
      "  2*Delta(log(L)) = 5238.95\n",
      "  Final MLGST took 0.3s\n",
      "  \n",
      "Iterative MLGST Total Time: 1.9s\n"
     ]
    }
   ],
   "source": [
    "gs_target.set_all_parameterizations(\"TP\")\n",
    "results = pygsti.do_long_sequence_gst(ds, gs_target, fiducials, fiducials,\n",
    "                                      germs, maxLengths, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, since we have a hunch that the reason for the bad fit is that when \"Gi\" follows \"Gx\" it looks different, we can fit that data to a model that has two identity gates, call them \"Gi\" and \"Gi2\" again, and tell GST to perform the \"GxGi => GxGi2\" manipulation rule before computing the probability of a gate sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gate Sequence Creation ---\n",
      " 1621 sequences created\n",
      " Dataset has 1585 entries: 1621 utilized, 0 requested sequences were missing\n",
      "--- LGST ---\n",
      "  Singular values of I_tilde (truncating to first 4 of 6) = \n",
      "  4.2440859008\n",
      "  1.16716001352\n",
      "  0.957280141699\n",
      "  0.94502768798\n",
      "  0.0226509425162\n",
      "  0.00873060801312\n",
      "  \n",
      "  Singular values of target I_tilde (truncating to first 4 of 6) = \n",
      "  4.24264068712\n",
      "  1.41421356237\n",
      "  1.41421356237\n",
      "  1.41421356237\n",
      "  3.03015102482e-16\n",
      "  7.09307430818e-17\n",
      "  \n",
      "--- Iterative MLGST: Iter 1 of 6  128 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 190.642 (128 data params - 43 model params = expected mean of 85; p-value = 4.43159e-10)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 190.298\n",
      "  Iteration 1 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 2 of 6  204 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 443.009 (204 data params - 43 model params = expected mean of 161; p-value = 0)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 440.995\n",
      "  Iteration 2 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 3 of 6  477 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 1290.71 (477 data params - 43 model params = expected mean of 434; p-value = 0)\n",
      "  Completed in 0.2s\n",
      "  2*Delta(log(L)) = 1281.36\n",
      "  Iteration 3 took 0.2s\n",
      "  \n",
      "--- Iterative MLGST: Iter 4 of 6  853 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 1872.05 (853 data params - 43 model params = expected mean of 810; p-value = 0)\n",
      "  Completed in 0.3s\n",
      "  2*Delta(log(L)) = 1864.41\n",
      "  Iteration 4 took 0.4s\n",
      "  \n",
      "--- Iterative MLGST: Iter 5 of 6  1237 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 2313.68 (1237 data params - 43 model params = expected mean of 1194; p-value = 0)\n",
      "  Completed in 0.5s\n",
      "  2*Delta(log(L)) = 2309.35\n",
      "  Iteration 5 took 0.5s\n",
      "  \n",
      "--- Iterative MLGST: Iter 6 of 6  1621 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 2746.6 (1621 data params - 43 model params = expected mean of 1578; p-value = 0)\n",
      "  Completed in 0.5s\n",
      "  2*Delta(log(L)) = 2742.35\n",
      "  Iteration 6 took 0.6s\n",
      "  \n",
      "  Switching to ML objective (last iteration)\n",
      "  --- MLGST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "    Maximum log(L) = 1370.65 below upper bound of -2.71224e+07\n",
      "      2*Delta(log(L)) = 2741.3 (1621 data params - 43 model params = expected mean of 1578; p-value = 0)\n",
      "    Completed in 0.5s\n",
      "  2*Delta(log(L)) = 2741.3\n",
      "  Final MLGST took 0.5s\n",
      "  \n",
      "Iterative MLGST Total Time: 2.5s\n"
     ]
    }
   ],
   "source": [
    "#Create a target gate set which includes a duplicate Gi called Gi2\n",
    "gs_targetB = gs_target.copy()\n",
    "gs_targetB['Gi2'] = gs_target['Gi'].copy() # Gi2 should just be another Gi\n",
    "\n",
    "#Run GST with:\n",
    "# 1) replacement rules giving instructions how to process all of the gate sequences\n",
    "# 2) data set aliases which replace labels in the *processed* strings before querying the DataSet.\n",
    "rules = [ ((\"Gx\",\"Gi\") , (\"Gx\",\"Gi2\")) ] # a single replacement rule: GxGi => GxGi2 \n",
    "resultsB = pygsti.do_long_sequence_gst(ds, gs_targetB, fiducials, fiducials,\n",
    "                                       germs, maxLengths, \n",
    "                                       advancedOptions={\"gateLabelAliases\": {'Gi2': ('Gi',)},\n",
    "                                                        \"stringManipRules\": rules},\n",
    "                                       verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a better fit, but not as good as it should (given that we know the data was generated from exactly the model being used).  This is due to the (default) LGST seed being a bad starting point, which can happen, particularly when looking for context dependence.  (The LGST estimate - which you can print using `print(resultsB.estimates['default'].gatesets['seed'])` - generates the *same* estimate for Gi and Gi2 which is roughly between the true values of Gi and Gi2, which can be a bad estimate for both gates.)  To instead use our own custom guess as the starting point, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gate Sequence Creation ---\n",
      " 1585 sequences created\n",
      " Dataset has 1585 entries: 1585 utilized, 0 requested sequences were missing\n",
      "--- Iterative MLGST: Iter 1 of 6  92 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 51.4367 (92 data params - 43 model params = expected mean of 49; p-value = 0.378543)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 51.4352\n",
      "  Iteration 1 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 2 of 6  168 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 134.323 (168 data params - 43 model params = expected mean of 125; p-value = 0.268452)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 134.297\n",
      "  Iteration 2 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 3 of 6  441 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 397.788 (441 data params - 43 model params = expected mean of 398; p-value = 0.493576)\n",
      "  Completed in 0.2s\n",
      "  2*Delta(log(L)) = 397.702\n",
      "  Iteration 3 took 0.2s\n",
      "  \n",
      "--- Iterative MLGST: Iter 4 of 6  817 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 786.998 (817 data params - 43 model params = expected mean of 774; p-value = 0.364877)\n",
      "  Completed in 0.3s\n",
      "  2*Delta(log(L)) = 786.924\n",
      "  Iteration 4 took 0.4s\n",
      "  \n",
      "--- Iterative MLGST: Iter 5 of 6  1201 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 1185.57 (1201 data params - 43 model params = expected mean of 1158; p-value = 0.280207)\n",
      "  Completed in 0.5s\n",
      "  2*Delta(log(L)) = 1185.41\n",
      "  Iteration 5 took 0.5s\n",
      "  \n",
      "--- Iterative MLGST: Iter 6 of 6  1585 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "  Sum of Chi^2 = 1627.59 (1585 data params - 43 model params = expected mean of 1542; p-value = 0.0635528)\n",
      "  Completed in 0.5s\n",
      "  2*Delta(log(L)) = 1627.51\n",
      "  Iteration 6 took 0.6s\n",
      "  \n",
      "  Switching to ML objective (last iteration)\n",
      "  --- MLGST ---\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "   groups of ~1 procs each, to distribute over 55 params (taken as 1 param groups of ~55 params).\n",
      "    Maximum log(L) = 813.749 below upper bound of -2.65382e+07\n",
      "      2*Delta(log(L)) = 1627.5 (1585 data params - 43 model params = expected mean of 1542; p-value = 0.0637617)\n",
      "    Completed in 0.3s\n",
      "  2*Delta(log(L)) = 1627.5\n",
      "  Final MLGST took 0.3s\n",
      "  \n",
      "Iterative MLGST Total Time: 2.2s\n"
     ]
    }
   ],
   "source": [
    "#Create a guess, which we'll use instead of LGST - here we just\n",
    "# take a slightly depolarized target.\n",
    "gs_start = gs_targetB.depolarize(gate_noise=0.01, spam_noise=0.01)\n",
    "\n",
    "#Run GST with the replacement rules as before.\n",
    "resultsC = pygsti.do_long_sequence_gst(ds, gs_targetB, fiducials, fiducials,\n",
    "                                       germs, maxLengths, \n",
    "                                       advancedOptions={\"gateLabelAliases\": {'Gi2': ('Gi',)},\n",
    "                                                        \"stringManipRules\": rules,\n",
    "                                                        \"starting point\": gs_start},\n",
    "                                       verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results is a much better fit and estimate, as seen from the final `2*Delta(log(L))` number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff between truth and standard GST:  0.0195172179758\n",
      "Diff between truth and context-dep GST w/LGST starting pt:  0.00497437109142\n",
      "Diff between truth and context-dep GST w/custom starting pt:  0.00143848720161\n"
     ]
    }
   ],
   "source": [
    "gsA = pygsti.gaugeopt_to_target(results.estimates['default'].gatesets['final iteration estimate'], gs_datagen)\n",
    "gsB = pygsti.gaugeopt_to_target(resultsB.estimates['default'].gatesets['final iteration estimate'], gs_datagen)\n",
    "gsC = pygsti.gaugeopt_to_target(resultsC.estimates['default'].gatesets['final iteration estimate'], gs_datagen)\n",
    "gsA['Gi2'] = gsA['Gi'] #so gsA is comparable with gs_datagen\n",
    "print(\"Diff between truth and standard GST: \", gs_datagen.frobeniusdist(gsA))\n",
    "print(\"Diff between truth and context-dep GST w/LGST starting pt: \", gs_datagen.frobeniusdist(gsB))\n",
    "print(\"Diff between truth and context-dep GST w/custom starting pt: \", gs_datagen.frobeniusdist(gsC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
