{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Generation Tutorial\n",
    "\n",
    "PyGSTi is able to construct polished report documents, which provide high-level summaries as well as detailed analyses of results (Gate Set Tomography (GST) and model-testing results in particular).  Reports are intended to be quick and easy way of analyzing `Model`-type estimates, and pyGSTi's report generation functions are specifically designed to interact with the `ModelEstimateResults` object (producted by several high-level algorithm functions - see, for example, the [GST overview tutorial](../algorithms/GST-Overview.ipynb) and [GST functions tutorial](../algorithms/GST-Drivers.ipynb).).  The report generation functions in pyGSTi takes one or more results (often `ModelEstimateResults`-type) objects as input and produces an HTML file as output.  The HTML format allows the reports to include **interactive plots** and **switches** (see the [workspace switchboard tutorial](advanced/WorkspaceSwitchboards.ipynb), making it easy to compare different types of analysis or data sets.  \n",
    "\n",
    "PyGSTi's reports are stand-alone HTML documents which cannot run Python.  Thus, all the results displayed in a report must be pre-computed (in Python).  If you find yourself wanting to fiddle with things and feel that these reports are too static, please consider using a `Workspace` object (see the [Workspace tutorial](Workspace.ipynb)) within a Jupyter notebook, where you can intermix report tables/plots and Python.  Internally, functions like `create_standard_report` (see below) are just canned routines which use a `WorkSpace` object to generate various tables and plots and then insert them into a HTML template.  \n",
    "\n",
    "\n",
    "### Get some `ModelEstimateResults`\n",
    "We start by performing GST using `do_long_sequence_gst`, as usual, to create a `ModelEstiamteResults` object (we could also have just loaded one from file).  See the [GST functions tutorial](../algorithms/GST-Driverfunctions.ipynb) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache file: ../tutorial_files/Example_Dataset.txt.cache\n",
      "--- Circuit Creation ---\n",
      "   616 sequences created\n",
      "--- LGST ---\n",
      "  Singular values of I_tilde (truncating to first 4 of 6) = \n",
      "  4.243708948119547\n",
      "  1.1796799227093193\n",
      "  0.9631622821716201\n",
      "  0.9415276081969872\n",
      "  0.04762148814438346\n",
      "  0.015427853978163288\n",
      "  \n",
      "  Singular values of target I_tilde (truncating to first 4 of 6) = \n",
      "  4.242640687119284\n",
      "  1.4142135623730956\n",
      "  1.4142135623730954\n",
      "  1.4142135623730951\n",
      "  2.5394445830714747e-16\n",
      "  1.118988490269554e-16\n",
      "  \n",
      "    Resulting model:\n",
      "    \n",
      "    rho0 = TPSPAMVec with dimension 4\n",
      "     0.71   0 0.03 0.75\n",
      "    \n",
      "    \n",
      "    Mdefault = TPPOVM with effect vectors:\n",
      "    0: FullSPAMVec with dimension 4\n",
      "     0.73   0   0 0.65\n",
      "    \n",
      "    1: ComplementSPAMVec with dimension 4\n",
      "     0.69   0   0-0.65\n",
      "    \n",
      "    \n",
      "    \n",
      "    [] = \n",
      "    TPDenseOp with shape (4, 4)\n",
      "     1.00   0   0   0\n",
      "       0 0.93-0.05 0.02\n",
      "       0 0.01 0.90 0.02\n",
      "       0 0.01   0 0.91\n",
      "    \n",
      "    \n",
      "    Gxpi2:0 = \n",
      "    TPDenseOp with shape (4, 4)\n",
      "     1.00   0   0   0\n",
      "       0 0.91   0   0\n",
      "    -0.02   0-0.04-1.00\n",
      "    -0.05 0.04 0.81   0\n",
      "    \n",
      "    \n",
      "    Gypi2:0 = \n",
      "    TPDenseOp with shape (4, 4)\n",
      "     1.00   0   0   0\n",
      "     0.03-0.02   0 0.98\n",
      "       0-0.01 0.89-0.03\n",
      "    -0.06-0.81   0 0.02\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "--- Iterative MLGST: Iter 1 of 5  92 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (92 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "    --- Outer Iter 0: norm_f = 82.5995, mu=1, |x|=2.96879, |J|=1630.54\n",
      "    --- Outer Iter 1: norm_f = 54.508, mu=260.251, |x|=2.978, |J|=4003\n",
      "    --- Outer Iter 2: norm_f = 53.5268, mu=86.7502, |x|=2.98092, |J|=4002.43\n",
      "    --- Outer Iter 3: norm_f = 53.5198, mu=28.9167, |x|=2.98131, |J|=4002.46\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "  Sum of Chi^2 = 53.5198 (92 data params - 31 model params = expected mean of 61; p-value = 0.740869)\n",
      "  Completed in 0.4s\n",
      "  2*Delta(log(L)) = 53.7539\n",
      "  Iteration 1 took 0.4s\n",
      "  \n",
      "--- Iterative MLGST: Iter 2 of 5  168 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (168 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "    --- Outer Iter 0: norm_f = 162.817, mu=1, |x|=2.98131, |J|=4118.3\n",
      "    --- Outer Iter 1: norm_f = 128.734, mu=1805.26, |x|=2.97343, |J|=4114.95\n",
      "    --- Outer Iter 2: norm_f = 123.035, mu=601.754, |x|=2.97016, |J|=4114.47\n",
      "    --- Outer Iter 3: norm_f = 122.413, mu=200.585, |x|=2.96944, |J|=4114.41\n",
      "    --- Outer Iter 4: norm_f = 122.392, mu=66.8616, |x|=2.96942, |J|=4114.42\n",
      "    --- Outer Iter 5: norm_f = 122.392, mu=22.2872, |x|=2.96942, |J|=4114.42\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "  Sum of Chi^2 = 122.392 (168 data params - 31 model params = expected mean of 137; p-value = 0.809296)\n",
      "  Completed in 0.4s\n",
      "  2*Delta(log(L)) = 122.796\n",
      "  Iteration 2 took 0.5s\n",
      "  \n",
      "--- Iterative MLGST: Iter 3 of 5  285 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (285 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "    --- Outer Iter 0: norm_f = 267.027, mu=1, |x|=2.96942, |J|=4309.94\n",
      "    --- Outer Iter 1: norm_f = 226.964, mu=1889.5, |x|=2.96655, |J|=4312.75\n",
      "    --- Outer Iter 2: norm_f = 225.915, mu=629.833, |x|=2.96615, |J|=4312.58\n",
      "    --- Outer Iter 3: norm_f = 225.901, mu=209.944, |x|=2.96616, |J|=4312.58\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "  Sum of Chi^2 = 225.901 (285 data params - 31 model params = expected mean of 254; p-value = 0.897248)\n",
      "  Completed in 0.5s\n",
      "  2*Delta(log(L)) = 226.203\n",
      "  Iteration 3 took 0.6s\n",
      "  \n",
      "--- Iterative MLGST: Iter 4 of 5  448 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (448 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "    --- Outer Iter 0: norm_f = 443.446, mu=1, |x|=2.96616, |J|=4652.53\n",
      "    --- Outer Iter 1: norm_f = 417.032, mu=2003.76, |x|=2.96528, |J|=4646.18\n",
      "    --- Outer Iter 2: norm_f = 416.63, mu=667.921, |x|=2.96532, |J|=4646.29\n",
      "    --- Outer Iter 3: norm_f = 416.625, mu=222.64, |x|=2.96533, |J|=4646.3\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "  Sum of Chi^2 = 416.625 (448 data params - 31 model params = expected mean of 417; p-value = 0.495964)\n",
      "  Completed in 0.8s\n",
      "  2*Delta(log(L)) = 417.12\n",
      "  Iteration 4 took 1.0s\n",
      "  \n",
      "--- Iterative MLGST: Iter 5 of 5  616 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (616 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "    --- Outer Iter 0: norm_f = 591.006, mu=1, |x|=2.96533, |J|=5095.69\n",
      "    --- Outer Iter 1: norm_f = 569.921, mu=2115.66, |x|=2.96469, |J|=5095.36\n",
      "    --- Outer Iter 2: norm_f = 569.869, mu=705.219, |x|=2.96476, |J|=5095.83\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "  Sum of Chi^2 = 569.869 (616 data params - 31 model params = expected mean of 585; p-value = 0.665202)\n",
      "  Completed in 1.0s\n",
      "  2*Delta(log(L)) = 570.489\n",
      "  Iteration 5 took 1.2s\n",
      "  \n",
      "  Switching to ML objective (last iteration)\n",
      "  --- MLGST ---\n",
      "    --- Outer Iter 0: norm_f = 285.244, mu=1, |x|=2.96476, |J|=2397.77\n",
      "    --- Outer Iter 1: norm_f = 285.244, mu=7.51801e+06, |x|=2.96476, |J|=2356.96\n",
      "    --- Outer Iter 2: norm_f = 285.243, mu=2.2554e+06, |x|=2.96477, |J|=2341.57\n",
      "    --- Outer Iter 3: norm_f = 285.242, mu=676621, |x|=2.96478, |J|=2495.82\n",
      "    --- Outer Iter 4: norm_f = 285.241, mu=1.29911e+07, |x|=2.96478, |J|=2425.79\n",
      "    --- Outer Iter 5: norm_f = 285.24, mu=3.89734e+06, |x|=2.96479, |J|=2340.71\n",
      "    --- Outer Iter 6: norm_f = 285.239, mu=1.1692e+06, |x|=2.9648, |J|=2346.15\n",
      "    --- Outer Iter 7: norm_f = 285.237, mu=350760, |x|=2.96483, |J|=2435.9\n",
      "    --- Outer Iter 8: norm_f = 285.236, mu=6.7346e+06, |x|=2.96483, |J|=2344.8\n",
      "    --- Outer Iter 9: norm_f = 285.236, mu=2.02038e+06, |x|=2.96483, |J|=2366.91\n",
      "    --- Outer Iter 10: norm_f = 285.235, mu=4.84891e+06, |x|=2.96483, |J|=2343.35\n",
      "    --- Outer Iter 11: norm_f = 285.235, mu=1.45467e+06, |x|=2.96484, |J|=2340.69\n",
      "    --- Outer Iter 12: norm_f = 285.234, mu=436402, |x|=2.96485, |J|=2403.74\n",
      "    --- Outer Iter 13: norm_f = 285.234, mu=8.37892e+06, |x|=2.96485, |J|=2363.05\n",
      "    --- Outer Iter 14: norm_f = 285.233, mu=2.51368e+06, |x|=2.96486, |J|=2341.19\n",
      "    --- Outer Iter 15: norm_f = 285.233, mu=1.50821e+06, |x|=2.96486, |J|=2373.36\n",
      "    --- Outer Iter 16: norm_f = 285.233, mu=3.61969e+06, |x|=2.96486, |J|=2341.12\n",
      "    --- Outer Iter 17: norm_f = 285.233, mu=1.08591e+06, |x|=2.96487, |J|=2355.65\n",
      "    --- Outer Iter 18: norm_f = 285.233, mu=2.60618e+06, |x|=2.96487, |J|=2340.59\n",
      "    --- Outer Iter 19: norm_f = 285.232, mu=1.56371e+06, |x|=2.96487, |J|=2358.78\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Maximum log(L) = 285.232 below upper bound of -1.02308e+06\n",
      "      2*Delta(log(L)) = 570.465 (616 data params - 31 model params = expected mean of 585; p-value = 0.658724)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Completed in 2.7s\n",
      "  2*Delta(log(L)) = 570.465\n",
      "  Final MLGST took 2.7s\n",
      "  \n",
      "Iterative MLGST Total Time: 6.4s\n",
      "    -- Performing 'go0' gauge optimization on default estimate --\n"
     ]
    }
   ],
   "source": [
    "import pygsti\n",
    "from pygsti.modelpacks import smq1Q_XYI\n",
    "\n",
    "target_model = smq1Q_XYI.target_model()\n",
    "prep_fiducials = smq1Q_XYI.prep_fiducials()\n",
    "meas_fiducials = smq1Q_XYI.meas_fiducials()\n",
    "germs = smq1Q_XYI.germs()\n",
    "maxLengths = [1,2,4,8,16]\n",
    "ds = pygsti.io.load_dataset(\"../tutorial_files/Example_Dataset.txt\", cache=True)\n",
    "\n",
    "#Run GST\n",
    "target_model.set_all_parameterizations(\"TP\") #TP-constrained\n",
    "results = pygsti.do_long_sequence_gst(ds, target_model, prep_fiducials, meas_fiducials, germs,\n",
    "                                      maxLengths, verbosity=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a report\n",
    "Now that we have `results`, we use the `create_standard_report` method within `pygsti.report` to generate a report.  \n",
    "`pygsti.report.create_standard_report` is the most commonly used report generation function in pyGSTi, as it is appropriate for smaller models (1- and 2-qubit) which have *operations that are or can be represeted as dense matrices and/or vectors*.  \n",
    "\n",
    "If the given filename ends in \"`.pdf`\" then a PDF-format report is generated; otherwise the file name specifies a folder that will be filled with HTML pages.  To open a HTML-format report, you open the `main.html` file directly inside the report's folder.  Setting `auto_open=True` makes the finished report open in your web browser automatically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n",
      "*** Report Generation Complete!  Total time 27.9991s ***\n",
      "\n",
      "\n",
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning:\n",
      "\n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/matplotlib/colors.py:504: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in less\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex file(s) successfully generated.  Attempting to compile with pdflatex...\n",
      "Opening ../tutorial_files/exampleReport.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR: pdflatex returned code 1 Check exampleReport.log to see details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Report Generation Complete!  Total time 71.7031s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x1290fc780>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HTML\n",
    "pygsti.report.create_standard_report(results, \"../tutorial_files/exampleReport\", \n",
    "                                     title=\"GST Example Report\", verbosity=1, auto_open=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#PDF\n",
    "pygsti.report.create_standard_report(results, \"../tutorial_files/exampleReport.pdf\", \n",
    "                                     title=\"GST Example Report\", verbosity=1, auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several remarks about these reports worth noting:\n",
    "1. The **HTML reports are the primary report type in pyGSTi**, and are much more flexible.  The PDF reports are more limited (they can only display a *single* estimate and gauge optimization), and essentially contain a subset of the information and descriptive text of a HTML report.  So, if you can, use the HTML reports.  The PDF report's strength is its portability: PDFs are easily displayed by many devices, and they embed all that they need neatly into a single file.  **If you need to generate a PDF report** from `Results` objects that have multiple estimates and/or gauge optimizations, consider using the `Results` object's `view` method to single out the estimate and gauge optimization you're after.\n",
    "2. It's best to use **Firefox** when opening the HTML reports. (If there's a problem with your brower's capabilities it will be shown on the screen when you try to load the report.)\n",
    "3. You'll need **`pdflatex`** on your system to compile PDF reports.\n",
    "4. To familiarize yourself with the layout of an HTML report, click on the gray **\"Help\" link** on the black sidebar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple estimates in a single report\n",
    "Next, let's analyze the same data two different ways: with and without the TP-constraint (i.e. whether the gates *must* be trace-preserving) and furthermore gauge optmimize each case using several different SPAM-weights.  In each case we'll call `do_long_sequence_gst` with `gaugeOptParams=False`, so that no gauge optimization is done, and then perform several gauge optimizations separately and add these to the `Results` object via its `add_gaugeoptimized` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Circuit Creation ---\n",
      "--- LGST ---\n",
      "--- Iterative MLGST: [##################################################] 100.0%  616 operation sequences ---\n",
      "Iterative MLGST Total Time: 6.1s\n"
     ]
    }
   ],
   "source": [
    "#Case1: TP-constrained GST\n",
    "tpTarget = target_model.copy()\n",
    "tpTarget.set_all_parameterizations(\"TP\")\n",
    "results_tp = pygsti.do_long_sequence_gst(ds, tpTarget, prep_fiducials, meas_fiducials, germs,\n",
    "                                      maxLengths, gaugeOptParams=False, verbosity=1)\n",
    "\n",
    "#Gauge optimize\n",
    "est = results_tp.estimates['default']\n",
    "mdlFinal = est.models['final iteration estimate']\n",
    "mdlTarget = est.models['target']\n",
    "for spamWt in [1e-4,1e-2,1.0]:\n",
    "    mdl = pygsti.gaugeopt_to_target(mdlFinal,mdlTarget,{'gates':1, 'spam':spamWt})\n",
    "    est.add_gaugeoptimized({'itemWeights': {'gates':1, 'spam':spamWt}}, mdl, \"Spam %g\" % spamWt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Circuit Creation ---\n",
      "--- LGST ---\n",
      "--- Iterative MLGST: [##################################################] 100.0%  616 operation sequences ---\n",
      "Iterative MLGST Total Time: 6.8s\n"
     ]
    }
   ],
   "source": [
    "#Case2: \"Full\" GST\n",
    "fullTarget = target_model.copy()\n",
    "fullTarget.set_all_parameterizations(\"full\")\n",
    "results_full = pygsti.do_long_sequence_gst(ds, fullTarget, prep_fiducials, meas_fiducials, germs,\n",
    "                                           maxLengths, gaugeOptParams=False, verbosity=1)\n",
    "\n",
    "#Gauge optimize\n",
    "est = results_full.estimates['default']\n",
    "mdlFinal = est.models['final iteration estimate']\n",
    "mdlTarget = est.models['target']\n",
    "for spamWt in [1e-4,1e-2,1.0]:\n",
    "    mdl = pygsti.gaugeopt_to_target(mdlFinal,mdlTarget,{'gates':1, 'spam':spamWt})\n",
    "    est.add_gaugeoptimized({'itemWeights': {'gates':1, 'spam':spamWt}}, mdl, \"Spam %g\" % spamWt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now call the *same* `create_standard_report` function but this time instead of passing a single `Results` object as the first argument we'll pass a *dictionary* of them.  This will result in a **HTML report that includes switches** to select which case (\"TP\" or \"Full\") as well as which gauge optimization to display output quantities for.  PDF reports cannot support this interactivity, and so **if you try to generate a PDF report you'll get an error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "  targetSpamBriefTable                          took 0.163411 seconds\n",
      "  targetGatesBoxTable                           took 0.20064 seconds\n",
      "  datasetOverviewTable                          took 0.130139 seconds\n",
      "  bestGatesetSpamParametersTable                took 0.001908 seconds\n",
      "  bestGatesetSpamBriefTable                     took 1.686359 seconds\n",
      "  bestGatesetSpamVsTargetTable                  took 0.419397 seconds\n",
      "  bestGatesetGaugeOptParamsTable                took 0.000572 seconds\n",
      "  bestGatesetGatesBoxTable                      took 1.129573 seconds\n",
      "  bestGatesetChoiEvalTable                      took 2.366403 seconds\n",
      "  bestGatesetDecompTable                        took 1.377133 seconds\n",
      "  bestGatesetEvalTable                          took 0.007271 seconds\n",
      "  bestGermsEvalTable                            took 0.018284 seconds\n",
      "  bestGatesetVsTargetTable                      took 0.182329 seconds\n",
      "  bestGatesVsTargetTable_gv                     took 1.253836 seconds\n",
      "  bestGatesVsTargetTable_gvgerms                took 0.141477 seconds\n",
      "  bestGatesVsTargetTable_gi                     took 0.016601 seconds\n",
      "  bestGatesVsTargetTable_gigerms                took 0.020124 seconds\n",
      "  bestGIGatesetTable                            took 3.866575 seconds\n",
      "  bestGatesVsTargetTable_sum                    took 1.180637 seconds\n",
      "  bestGatesetErrGenBoxTable                     took 5.470322 seconds\n",
      "  metadataTable                                 took 0.004553 seconds\n",
      "  stdoutBlock                                   took 0.000319 seconds\n",
      "  profilerTable                                 took 0.001686 seconds\n",
      "  softwareEnvTable                              took 0.003274 seconds\n",
      "  exampleTable                                  took 0.06354 seconds\n",
      "  singleMetricTable_gv                          took 1.261608 seconds\n",
      "  singleMetricTable_gi                          took 0.051045 seconds\n",
      "  bestGIMetricTable                             took 9.314711 seconds\n",
      "  fiducialListTable                             took 0.000728 seconds\n",
      "  prepStrListTable                              took 0.00028 seconds\n",
      "  effectStrListTable                            took 0.000277 seconds\n",
      "  colorBoxPlotKeyPlot                           took 0.069442 seconds\n",
      "  germList2ColTable                             took 0.000391 seconds\n",
      "  progressTable                                 took 4.55075 seconds\n",
      "*** Generating plots ***\n",
      "  gramBarPlot                                   took 0.21073 seconds\n",
      "  progressBarPlot                               took 1.50193 seconds\n",
      "  progressBarPlot_sum                           took 0.001193 seconds\n",
      "  finalFitComparePlot                           took 0.631949 seconds\n",
      "  bestEstimateColorBoxPlot                      took 15.241346 seconds\n",
      "  bestEstimateTVDColorBoxPlot                   took 5.184299 seconds\n",
      "  bestEstimateColorScatterPlot                  took 2.9882 seconds\n",
      "  bestEstimateColorHistogram                    took 1.902466 seconds\n",
      "  progressTable_scl                             took 9.5e-05 seconds\n",
      "  progressBarPlot_scl                           took 9.4e-05 seconds\n",
      "  bestEstimateColorBoxPlot_scl                  took 0.000231 seconds\n",
      "  bestEstimateColorScatterPlot_scl              took 0.000391 seconds\n",
      "  bestEstimateColorHistogram_scl                took 0.000425 seconds\n",
      "  progressTable_ume                             took 0.000132 seconds\n",
      "  progressBarPlot_ume                           took 0.00014 seconds\n",
      "  bestEstimateColorBoxPlot_ume                  took 0.000515 seconds\n",
      "  bestEstimateColorScatterPlot_ume              took 0.000436 seconds\n",
      "  bestEstimateColorHistogram_ume                took 0.000446 seconds\n",
      "  dataScalingColorBoxPlot                       took 0.000123 seconds\n",
      "  unmodeledErrorBudgetTable                     took 8.7e-05 seconds\n",
      "Statistical hypothesis tests did NOT find inconsistency between the datasets at 5.00% significance.\n",
      "Statistical hypothesis tests did NOT find inconsistency between the datasets at 5.00% significance.\n",
      "Statistical hypothesis tests did NOT find inconsistency between the datasets at 5.00% significance.\n",
      "Statistical hypothesis tests did NOT find inconsistency between the datasets at 5.00% significance.\n",
      "  dsComparisonSummary                           took 0.181227 seconds\n",
      "  dsComparisonHistogram                         took 0.5311 seconds\n",
      "  dsComparisonBoxPlot                           took 0.470404 seconds\n",
      "*** Merging into template file ***\n",
      "*** Report Generation Complete!  Total time 80.6172s ***\n"
     ]
    }
   ],
   "source": [
    "ws = pygsti.report.create_standard_report({'TP': results_tp, \"Full\": results_full},\n",
    "                                         \"../tutorial_files/exampleMultiEstimateReport\",\n",
    "                                         title=\"Example Multi-Estimate Report\", \n",
    "                                         verbosity=2, auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the above call we capture the return value in the variable `ws` - a `Workspace` object.  PyGSTi's `Workspace` objects function as both a factory for figures and tables as well as a smart cache for computed values.  Within `create_standard_report` a `Workspace` object is created and used to create all the figures in the report.  As an intended side effect, each of these figures is cached, along with some of the intermediate results used to create it.  As we'll see below, a `Workspace` can also be specified as input to `create_standard_report`, allowing it to utilize previously cached quantities.\n",
    "\n",
    "**Another way**: Because both `results_tp` and `results_full` above used the same dataset and operation sequences, we could have combined them as two estimates in a single `ModelEstimateResults` object (see the previous tutorial on pyGSTi's results objects).  This can be done by renaming at least one of the `\"default\"`-named estimates in `results_tp` or `results_full` (below we rename both) and then adding the estimate within `results_full` to the estimates already contained in `results_tp`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tp.rename_estimate('default','TP')\n",
    "results_full.rename_estimate('default','Full')\n",
    "results_both = results_tp.copy() #copy just for neatness\n",
    "results_both.add_estimates(results_full, estimatesToAdd=['Full'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a report using `results_both` will result in the same report we just generated.  We'll demonstrate this anyway, but in addition we'll supply `create_standard_report` a `ws` argument, which tells it to use any cached values contained in a given *input* `Workspace` to expedite report generation.  Since our workspace object has the exact quantities we need cached in it, you'll notice a significant speedup.  Finally, note that even though there's just a single `Results` object, you **still can't generate a PDF report** from it because it contains multiple estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "  targetSpamBriefTable                          took 0.000542 seconds\n",
      "  targetGatesBoxTable                           took 0.000429 seconds\n",
      "  datasetOverviewTable                          took 0.000235 seconds\n",
      "  bestGatesetSpamParametersTable                took 0.00114 seconds\n",
      "  bestGatesetSpamBriefTable                     took 0.001881 seconds\n",
      "  bestGatesetSpamVsTargetTable                  took 0.00101 seconds\n",
      "  bestGatesetGaugeOptParamsTable                took 0.000526 seconds\n",
      "  bestGatesetGatesBoxTable                      took 0.001063 seconds\n",
      "  bestGatesetChoiEvalTable                      took 0.00088 seconds\n",
      "  bestGatesetDecompTable                        took 0.001053 seconds\n",
      "  bestGatesetEvalTable                          took 0.000334 seconds\n",
      "  bestGermsEvalTable                            took 0.018828 seconds\n",
      "  bestGatesetVsTargetTable                      took 0.005626 seconds\n",
      "  bestGatesVsTargetTable_gv                     took 0.001437 seconds\n",
      "  bestGatesVsTargetTable_gvgerms                took 0.001582 seconds\n",
      "  bestGatesVsTargetTable_gi                     took 0.00054 seconds\n",
      "  bestGatesVsTargetTable_gigerms                took 0.023123 seconds\n",
      "  bestGIGatesetTable                            took 0.001122 seconds\n",
      "  bestGatesVsTargetTable_sum                    took 0.001479 seconds\n",
      "  bestGatesetErrGenBoxTable                     took 0.001407 seconds\n",
      "  metadataTable                                 took 0.002601 seconds\n",
      "  stdoutBlock                                   took 0.000114 seconds\n",
      "  profilerTable                                 took 0.000846 seconds\n",
      "  softwareEnvTable                              took 0.000124 seconds\n",
      "  exampleTable                                  took 8.4e-05 seconds\n",
      "  singleMetricTable_gv                          took 1.354431 seconds\n",
      "  singleMetricTable_gi                          took 0.058709 seconds\n",
      "  bestGIMetricTable                             took 0.008878 seconds\n",
      "  fiducialListTable                             took 0.000224 seconds\n",
      "  prepStrListTable                              took 0.000494 seconds\n",
      "  effectStrListTable                            took 0.000287 seconds\n",
      "  colorBoxPlotKeyPlot                           took 0.000389 seconds\n",
      "  germList2ColTable                             took 0.00015 seconds\n",
      "  progressTable                                 took 0.737461 seconds\n",
      "*** Generating plots ***\n",
      "  gramBarPlot                                   took 0.000823 seconds\n",
      "  progressBarPlot                               took 0.785746 seconds\n",
      "  progressBarPlot_sum                           took 0.000994 seconds\n",
      "  finalFitComparePlot                           took 0.069885 seconds\n",
      "  bestEstimateColorBoxPlot                      took 8.963703 seconds\n",
      "  bestEstimateTVDColorBoxPlot                   took 3.018054 seconds\n",
      "  bestEstimateColorScatterPlot                  took 1.665656 seconds\n",
      "  bestEstimateColorHistogram                    took 0.880838 seconds\n",
      "  progressTable_scl                             took 0.000102 seconds\n",
      "  progressBarPlot_scl                           took 9e-05 seconds\n",
      "  bestEstimateColorBoxPlot_scl                  took 0.000257 seconds\n",
      "  bestEstimateColorScatterPlot_scl              took 0.00027 seconds\n",
      "  bestEstimateColorHistogram_scl                took 0.000474 seconds\n",
      "  progressTable_ume                             took 0.000107 seconds\n",
      "  progressBarPlot_ume                           took 0.000185 seconds\n",
      "  bestEstimateColorBoxPlot_ume                  took 0.000318 seconds\n",
      "  bestEstimateColorScatterPlot_ume              took 0.000315 seconds\n",
      "  bestEstimateColorHistogram_ume                took 0.000525 seconds\n",
      "  dataScalingColorBoxPlot                       took 8.9e-05 seconds\n",
      "  unmodeledErrorBudgetTable                     took 9.9e-05 seconds\n",
      "*** Merging into template file ***\n",
      "*** Report Generation Complete!  Total time 31.6821s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x12de81588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygsti.report.create_standard_report(results_both,\n",
    "                                     \"../tutorial_files/exampleMultiEstimateReport2\",\n",
    "                                     title=\"Example Multi-Estimate Report (v2)\", \n",
    "                                     verbosity=2, auto_open=True, ws=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple estimates and `do_stdpractice_gst`\n",
    "It's no coincidence that a `Results` object containing multiple estimates using the same data is precisely what's returned from `do_stdpractice_gst` (see docstring for information on its arguments, and see the [GST functions tutorial](../algorithms/GST-Drivers.ipynb)).  This allows one to run GST multiple times, creating several different \"standard\" estimates and gauge optimizations, and plot them all in a single (HTML) report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Circuit Creation ---\n",
      "   616 sequences created\n",
      "-- Std Practice:  Iter 1 of 3  (TP) --: \n",
      "  --- Iterative MLGST: Iter 1 of 5  92 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (92 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "      --- Outer Iter 0: norm_f = 1.10824e+07, mu=1, |x|=3.24037, |J|=35582.1\n",
      "      --- Outer Iter 1: norm_f = 303.428, mu=51712.5, |x|=3.05021, |J|=1134.91\n",
      "      --- Outer Iter 2: norm_f = 121.277, mu=17237.5, |x|=3.03189, |J|=1044.18\n",
      "      --- Outer Iter 3: norm_f = 84.3233, mu=5745.83, |x|=3.01957, |J|=1032.63\n",
      "      --- Outer Iter 4: norm_f = 63.5765, mu=1915.28, |x|=3.00506, |J|=1097.04\n",
      "      --- Outer Iter 5: norm_f = 60.8189, mu=10066.5, |x|=3.001, |J|=4005.46\n",
      "      --- Outer Iter 6: norm_f = 58.095, mu=3355.51, |x|=2.9974, |J|=4004.3\n",
      "      --- Outer Iter 7: norm_f = 55.8443, mu=1118.5, |x|=2.99167, |J|=4003.98\n",
      "      --- Outer Iter 8: norm_f = 54.09, mu=372.834, |x|=2.98531, |J|=4003.77\n",
      "      --- Outer Iter 9: norm_f = 53.5615, mu=124.278, |x|=2.98201, |J|=4003.69\n",
      "      --- Outer Iter 10: norm_f = 53.5204, mu=41.426, |x|=2.98138, |J|=4003.68\n",
      "      --- Outer Iter 11: norm_f = 53.5198, mu=13.8087, |x|=2.98133, |J|=4003.68\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 53.5198 (92 data params - 31 model params = expected mean of 61; p-value = 0.74087)\n",
      "    Completed in 0.5s\n",
      "    2*Delta(log(L)) = 53.7539\n",
      "    Iteration 1 took 0.5s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 2 of 5  168 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (168 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "      --- Outer Iter 0: norm_f = 162.896, mu=1, |x|=2.98133, |J|=4119.6\n",
      "      --- Outer Iter 1: norm_f = 128.768, mu=1805.26, |x|=2.97343, |J|=4116.24\n",
      "      --- Outer Iter 2: norm_f = 123.042, mu=601.754, |x|=2.97016, |J|=4115.76\n",
      "      --- Outer Iter 3: norm_f = 122.413, mu=200.585, |x|=2.96944, |J|=4115.7\n",
      "      --- Outer Iter 4: norm_f = 122.392, mu=66.8616, |x|=2.96941, |J|=4115.71\n",
      "      --- Outer Iter 5: norm_f = 122.392, mu=22.2872, |x|=2.96942, |J|=4115.71\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 122.392 (168 data params - 31 model params = expected mean of 137; p-value = 0.809296)\n",
      "    Completed in 0.4s\n",
      "    2*Delta(log(L)) = 122.796\n",
      "    Iteration 2 took 0.4s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 3 of 5  285 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (285 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "      --- Outer Iter 0: norm_f = 267.027, mu=1, |x|=2.96942, |J|=4311.43\n",
      "      --- Outer Iter 1: norm_f = 226.967, mu=1889.5, |x|=2.96655, |J|=4314.25\n",
      "      --- Outer Iter 2: norm_f = 225.915, mu=629.833, |x|=2.96614, |J|=4314.08\n",
      "      --- Outer Iter 3: norm_f = 225.901, mu=209.944, |x|=2.96616, |J|=4314.08\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 225.901 (285 data params - 31 model params = expected mean of 254; p-value = 0.897248)\n",
      "    Completed in 0.5s\n",
      "    2*Delta(log(L)) = 226.203\n",
      "    Iteration 3 took 0.6s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 4 of 5  448 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (448 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "      --- Outer Iter 0: norm_f = 443.445, mu=1, |x|=2.96616, |J|=4654.5\n",
      "      --- Outer Iter 1: norm_f = 417.033, mu=2003.76, |x|=2.96528, |J|=4648.14\n",
      "      --- Outer Iter 2: norm_f = 416.63, mu=667.921, |x|=2.96532, |J|=4648.24\n",
      "      --- Outer Iter 3: norm_f = 416.625, mu=222.64, |x|=2.96532, |J|=4648.25\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 416.625 (448 data params - 31 model params = expected mean of 417; p-value = 0.495964)\n",
      "    Completed in 0.7s\n",
      "    2*Delta(log(L)) = 417.12\n",
      "    Iteration 4 took 0.9s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 5 of 5  616 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (616 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 43 params (taken as 1 param groups of ~43 params).\n",
      "      --- Outer Iter 0: norm_f = 591.006, mu=1, |x|=2.96532, |J|=5098.46\n",
      "      --- Outer Iter 1: norm_f = 569.921, mu=2115.66, |x|=2.96469, |J|=5098.12\n",
      "      --- Outer Iter 2: norm_f = 569.869, mu=705.219, |x|=2.96476, |J|=5098.58\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 569.869 (616 data params - 31 model params = expected mean of 585; p-value = 0.665202)\n",
      "    Completed in 1.0s\n",
      "    2*Delta(log(L)) = 570.489\n",
      "    Iteration 5 took 1.2s\n",
      "    \n",
      "    Switching to ML objective (last iteration)\n",
      "    --- MLGST ---\n",
      "      --- Outer Iter 0: norm_f = 285.244, mu=1, |x|=2.96476, |J|=2399.78\n",
      "      --- Outer Iter 1: norm_f = 285.244, mu=7.51794e+06, |x|=2.96476, |J|=2358.96\n",
      "      --- Outer Iter 2: norm_f = 285.243, mu=2.25538e+06, |x|=2.96477, |J|=2343.59\n",
      "      --- Outer Iter 3: norm_f = 285.242, mu=676615, |x|=2.96478, |J|=2498.05\n",
      "      --- Outer Iter 4: norm_f = 285.241, mu=1.2991e+07, |x|=2.96478, |J|=2427.9\n",
      "      --- Outer Iter 5: norm_f = 285.24, mu=3.8973e+06, |x|=2.96479, |J|=2342.73\n",
      "      --- Outer Iter 6: norm_f = 285.239, mu=1.16919e+06, |x|=2.9648, |J|=2348.24\n",
      "      --- Outer Iter 7: norm_f = 285.237, mu=350757, |x|=2.96483, |J|=2440.63\n",
      "      --- Outer Iter 8: norm_f = 285.236, mu=6.73453e+06, |x|=2.96482, |J|=2346.98\n",
      "      --- Outer Iter 9: norm_f = 285.236, mu=2.02036e+06, |x|=2.96483, |J|=2369.39\n",
      "      --- Outer Iter 10: norm_f = 285.235, mu=4.84886e+06, |x|=2.96483, |J|=2345.38\n",
      "      --- Outer Iter 11: norm_f = 285.235, mu=1.45466e+06, |x|=2.96483, |J|=2342.7\n",
      "      --- Outer Iter 12: norm_f = 285.234, mu=436398, |x|=2.96485, |J|=2406.82\n",
      "      --- Outer Iter 13: norm_f = 285.234, mu=8.37884e+06, |x|=2.96485, |J|=2365.4\n",
      "      --- Outer Iter 14: norm_f = 285.233, mu=2.51365e+06, |x|=2.96486, |J|=2343.26\n",
      "      --- Outer Iter 15: norm_f = 285.233, mu=1.50819e+06, |x|=2.96486, |J|=2375.95\n",
      "      --- Outer Iter 16: norm_f = 285.233, mu=3.61966e+06, |x|=2.96486, |J|=2343.12\n",
      "      --- Outer Iter 17: norm_f = 285.233, mu=1.0859e+06, |x|=2.96487, |J|=2357.9\n",
      "      --- Outer Iter 18: norm_f = 285.233, mu=2.60615e+06, |x|=2.96487, |J|=2342.61\n",
      "      --- Outer Iter 19: norm_f = 285.232, mu=1.56369e+06, |x|=2.96487, |J|=2361.12\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "      Maximum log(L) = 285.232 below upper bound of -1.02308e+06\n",
      "        2*Delta(log(L)) = 570.465 (616 data params - 31 model params = expected mean of 585; p-value = 0.658724)\n",
      "      Completed in 2.5s\n",
      "    2*Delta(log(L)) = 570.465\n",
      "    Final MLGST took 2.5s\n",
      "    \n",
      "  Iterative MLGST Total Time: 6.1s\n",
      "      -- Performing 'stdgaugeopt' gauge optimization on TP estimate --\n",
      "      -- Performing 'Spam 0.001' gauge optimization on TP estimate --\n",
      "      -- Performing 'Spam 0.001+v' gauge optimization on TP estimate --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Std Practice:  Iter 2 of 3  (CPTP) --: \n",
      "  --- Iterative MLGST: Iter 1 of 5  92 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (92 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 60 params (taken as 1 param groups of ~60 params).\n",
      "      --- Outer Iter 0: norm_f = 1.10824e+07, mu=1, |x|=3.87298e-08, |J|=776.628\n",
      "      --- Outer Iter 1: norm_f = 13896.2, mu=76.022, |x|=0.186556, |J|=1603.59\n",
      "      --- Outer Iter 2: norm_f = 691.025, mu=25.3407, |x|=0.395611, |J|=805.502\n",
      "      --- Outer Iter 3: norm_f = 305.58, mu=25.0676, |x|=0.576073, |J|=636.635\n",
      "      --- Outer Iter 4: norm_f = 60.9768, mu=8.35586, |x|=0.488447, |J|=684.947\n",
      "      --- Outer Iter 5: norm_f = 54.6428, mu=5.67173, |x|=0.481138, |J|=692.277\n",
      "      --- Outer Iter 6: norm_f = 54.1427, mu=363.222, |x|=0.479168, |J|=693.573\n",
      "      --- Outer Iter 7: norm_f = 53.9755, mu=743.052, |x|=0.478533, |J|=694.019\n",
      "      --- Outer Iter 8: norm_f = 53.9567, mu=1177.28, |x|=0.478295, |J|=694.245\n",
      "      --- Outer Iter 9: norm_f = 53.8927, mu=1196.39, |x|=0.478177, |J|=694.258\n",
      "      --- Outer Iter 10: norm_f = 53.8769, mu=1223.92, |x|=0.47807, |J|=694.354\n",
      "      --- Outer Iter 11: norm_f = 53.8676, mu=1228.91, |x|=0.478049, |J|=694.378\n",
      "      --- Outer Iter 12: norm_f = 53.8605, mu=1228.39, |x|=0.478041, |J|=694.396\n",
      "      --- Outer Iter 13: norm_f = 53.8545, mu=1179.52, |x|=0.478035, |J|=694.414\n",
      "      --- Outer Iter 14: norm_f = 53.8488, mu=970.374, |x|=0.47803, |J|=694.434\n",
      "      --- Outer Iter 15: norm_f = 53.8423, mu=720.574, |x|=0.478026, |J|=694.458\n",
      "      --- Outer Iter 16: norm_f = 53.8346, mu=685.806, |x|=0.478023, |J|=694.493\n",
      "      --- Outer Iter 17: norm_f = 53.8302, mu=789.146, |x|=0.478026, |J|=694.542\n",
      "      --- Outer Iter 18: norm_f = 53.8202, mu=1578.36, |x|=0.478019, |J|=694.547\n",
      "      --- Outer Iter 19: norm_f = 53.8155, mu=1168.52, |x|=0.478007, |J|=694.574\n",
      "      --- Outer Iter 20: norm_f = 53.8097, mu=389.506, |x|=0.478006, |J|=694.599\n",
      "      --- Outer Iter 21: norm_f = 53.7938, mu=131.864, |x|=0.478033, |J|=694.651\n",
      "      --- Outer Iter 22: norm_f = 53.7875, mu=1022.13, |x|=0.478026, |J|=694.704\n",
      "      --- Outer Iter 23: norm_f = 53.7812, mu=996.247, |x|=0.478032, |J|=694.738\n",
      "      --- Outer Iter 24: norm_f = 53.7749, mu=985.592, |x|=0.478042, |J|=694.772\n",
      "      --- Outer Iter 25: norm_f = 53.7688, mu=984.38, |x|=0.478055, |J|=694.808\n",
      "      --- Outer Iter 26: norm_f = 53.7628, mu=984.388, |x|=0.478072, |J|=694.844\n",
      "      --- Outer Iter 27: norm_f = 53.757, mu=987.277, |x|=0.478091, |J|=694.88\n",
      "      --- Outer Iter 28: norm_f = 53.7515, mu=1003.29, |x|=0.478113, |J|=694.917\n",
      "      --- Outer Iter 29: norm_f = 53.7461, mu=1038.06, |x|=0.478137, |J|=694.953\n",
      "      --- Outer Iter 30: norm_f = 53.7406, mu=1077.24, |x|=0.478162, |J|=694.988\n",
      "      --- Outer Iter 31: norm_f = 53.7351, mu=1101.5, |x|=0.478187, |J|=695.021\n",
      "      --- Outer Iter 32: norm_f = 53.7298, mu=1109.51, |x|=0.478213, |J|=695.054\n",
      "      --- Outer Iter 33: norm_f = 53.7248, mu=1110.28, |x|=0.478242, |J|=695.087\n",
      "      --- Outer Iter 34: norm_f = 53.72, mu=1110.27, |x|=0.478273, |J|=695.122\n",
      "      --- Outer Iter 35: norm_f = 53.7155, mu=1108.23, |x|=0.478307, |J|=695.157\n",
      "      --- Outer Iter 36: norm_f = 53.7111, mu=1096.74, |x|=0.478344, |J|=695.193\n",
      "      --- Outer Iter 37: norm_f = 53.7069, mu=1067.61, |x|=0.478383, |J|=695.229\n",
      "      --- Outer Iter 38: norm_f = 53.7028, mu=1024.27, |x|=0.478426, |J|=695.268\n",
      "      --- Outer Iter 39: norm_f = 53.6988, mu=987.129, |x|=0.478473, |J|=695.308\n",
      "      --- Outer Iter 40: norm_f = 53.6948, mu=972.855, |x|=0.478525, |J|=695.351\n",
      "      --- Outer Iter 41: norm_f = 53.6911, mu=971.937, |x|=0.478581, |J|=695.395\n",
      "      --- Outer Iter 42: norm_f = 53.6875, mu=972.228, |x|=0.478639, |J|=695.44\n",
      "      --- Outer Iter 43: norm_f = 53.6842, mu=983.06, |x|=0.478699, |J|=695.485\n",
      "      --- Outer Iter 44: norm_f = 53.681, mu=1024.46, |x|=0.478761, |J|=695.531\n",
      "      --- Outer Iter 45: norm_f = 53.6778, mu=1084.25, |x|=0.478822, |J|=695.572\n",
      "      --- Outer Iter 46: norm_f = 53.6745, mu=1123.54, |x|=0.47888, |J|=695.61\n",
      "      --- Outer Iter 47: norm_f = 53.6712, mu=1135.1, |x|=0.478937, |J|=695.646\n",
      "      --- Outer Iter 48: norm_f = 53.6682, mu=1135.64, |x|=0.478995, |J|=695.684\n",
      "      --- Outer Iter 49: norm_f = 53.6653, mu=1135.25, |x|=0.479056, |J|=695.721\n",
      "      --- Outer Iter 50: norm_f = 53.6625, mu=1124.07, |x|=0.479119, |J|=695.759\n",
      "      --- Outer Iter 51: norm_f = 53.6598, mu=1079.07, |x|=0.479184, |J|=695.798\n",
      "      --- Outer Iter 52: norm_f = 53.6572, mu=996.615, |x|=0.479253, |J|=695.839\n",
      "      --- Outer Iter 53: norm_f = 53.6545, mu=925.805, |x|=0.479331, |J|=695.884\n",
      "      --- Outer Iter 54: norm_f = 53.6517, mu=908.918, |x|=0.479416, |J|=695.934\n",
      "      --- Outer Iter 55: norm_f = 53.6492, mu=908.92, |x|=0.479505, |J|=695.984\n",
      "      --- Outer Iter 56: norm_f = 53.6469, mu=935.867, |x|=0.479595, |J|=696.038\n",
      "      --- Outer Iter 57: norm_f = 53.6448, mu=1066.26, |x|=0.479684, |J|=696.087\n",
      "      --- Outer Iter 58: norm_f = 53.6412, mu=1082.15, |x|=0.479762, |J|=697.237\n",
      "      --- Outer Iter 59: norm_f = 53.6385, mu=1651.74, |x|=0.479898, |J|=697.393\n",
      "      --- Outer Iter 60: norm_f = 53.6302, mu=1986.33, |x|=0.479978, |J|=697.263\n",
      "      --- Outer Iter 61: norm_f = 53.6227, mu=2052.45, |x|=0.480032, |J|=697.123\n",
      "      --- Outer Iter 62: norm_f = 53.6186, mu=2053.34, |x|=0.480088, |J|=697.084\n",
      "      --- Outer Iter 63: norm_f = 53.6157, mu=1993.61, |x|=0.480148, |J|=697.077\n",
      "      --- Outer Iter 64: norm_f = 53.6132, mu=1420.1, |x|=0.48021, |J|=697.086\n",
      "      --- Outer Iter 65: norm_f = 53.6102, mu=692.049, |x|=0.480297, |J|=697.107\n",
      "      --- Outer Iter 66: norm_f = 53.6053, mu=623.755, |x|=0.480475, |J|=697.188\n",
      "      --- Outer Iter 67: norm_f = 53.603, mu=1331, |x|=0.48057, |J|=697.247\n",
      "      --- Outer Iter 68: norm_f = 53.6007, mu=1520.39, |x|=0.480658, |J|=697.291\n",
      "      --- Outer Iter 69: norm_f = 53.5977, mu=1598.92, |x|=0.480734, |J|=697.285\n",
      "      --- Outer Iter 70: norm_f = 53.595, mu=1606.92, |x|=0.480807, |J|=697.283\n",
      "      --- Outer Iter 71: norm_f = 53.5926, mu=1606.02, |x|=0.48088, |J|=697.288\n",
      "      --- Outer Iter 72: norm_f = 53.5905, mu=1533.46, |x|=0.480955, |J|=697.302\n",
      "      --- Outer Iter 73: norm_f = 53.5884, mu=1231.43, |x|=0.481032, |J|=697.319\n",
      "      --- Outer Iter 74: norm_f = 53.586, mu=879.28, |x|=0.481129, |J|=697.348\n",
      "      --- Outer Iter 75: norm_f = 53.5832, mu=825.706, |x|=0.481263, |J|=697.4\n",
      "      --- Outer Iter 76: norm_f = 53.5817, mu=938.993, |x|=0.481401, |J|=697.513\n",
      "      --- Outer Iter 77: norm_f = 53.5816, mu=1856.86, |x|=0.481519, |J|=697.652\n",
      "      --- Outer Iter 78: norm_f = 53.576, mu=1858.26, |x|=0.481573, |J|=697.488\n",
      "      --- Outer Iter 79: norm_f = 53.5745, mu=1597.05, |x|=0.481629, |J|=697.489\n",
      "      --- Outer Iter 80: norm_f = 53.573, mu=532.35, |x|=0.481699, |J|=697.505\n",
      "      --- Outer Iter 81: norm_f = 53.569, mu=177.45, |x|=0.481907, |J|=697.559\n",
      "      --- Outer Iter 82: norm_f = 53.5661, mu=355.278, |x|=0.482201, |J|=697.757\n",
      "      --- Outer Iter 83: norm_f = 53.5631, mu=2713.17, |x|=0.482231, |J|=697.658\n",
      "      --- Outer Iter 84: norm_f = 53.5623, mu=1330.2, |x|=0.482267, |J|=697.663\n",
      "      --- Outer Iter 85: norm_f = 53.561, mu=443.4, |x|=0.482343, |J|=697.683\n",
      "      --- Outer Iter 86: norm_f = 53.5575, mu=147.8, |x|=0.482566, |J|=697.741\n",
      "      --- Outer Iter 87: norm_f = 53.5521, mu=146.74, |x|=0.483171, |J|=698.045\n",
      "      --- Outer Iter 88: norm_f = 53.5487, mu=1184.96, |x|=0.483221, |J|=697.962\n",
      "      --- Outer Iter 89: norm_f = 53.5475, mu=1183.83, |x|=0.483285, |J|=697.961\n",
      "      --- Outer Iter 90: norm_f = 53.5466, mu=972.429, |x|=0.483353, |J|=697.976\n",
      "      --- Outer Iter 91: norm_f = 53.5456, mu=434.966, |x|=0.483436, |J|=697.999\n",
      "      --- Outer Iter 92: norm_f = 53.5437, mu=264.976, |x|=0.483616, |J|=698.058\n",
      "      --- Outer Iter 93: norm_f = 53.5427, mu=532.383, |x|=0.483755, |J|=698.133\n",
      "      --- Outer Iter 94: norm_f = 53.5415, mu=1065.04, |x|=0.483821, |J|=698.123\n",
      "      --- Outer Iter 95: norm_f = 53.5407, mu=982.855, |x|=0.483887, |J|=698.135\n",
      "      --- Outer Iter 96: norm_f = 53.5399, mu=517.316, |x|=0.483959, |J|=698.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      --- Outer Iter 97: norm_f = 53.5387, mu=221.519, |x|=0.484091, |J|=698.195\n",
      "      --- Outer Iter 98: norm_f = 53.5374, mu=223.108, |x|=0.484378, |J|=698.372\n",
      "      --- Outer Iter 99: norm_f = 53.5359, mu=1715.96, |x|=0.484407, |J|=698.296\n",
      "      --- Outer Iter 100: norm_f = 53.5356, mu=875.91, |x|=0.484441, |J|=698.302\n",
      "      --- Outer Iter 101: norm_f = 53.535, mu=291.97, |x|=0.484509, |J|=698.323\n",
      "      --- Outer Iter 102: norm_f = 53.5335, mu=97.3233, |x|=0.484706, |J|=698.382\n",
      "      --- Outer Iter 103: norm_f = 53.531, mu=91.1406, |x|=0.485215, |J|=698.6\n",
      "      --- Outer Iter 104: norm_f = 53.53, mu=734.775, |x|=0.485262, |J|=698.582\n",
      "      --- Outer Iter 105: norm_f = 53.5295, mu=732.038, |x|=0.48532, |J|=698.591\n",
      "      --- Outer Iter 106: norm_f = 53.5291, mu=567.125, |x|=0.485379, |J|=698.608\n",
      "      --- Outer Iter 107: norm_f = 53.5287, mu=241.708, |x|=0.485455, |J|=698.633\n",
      "      --- Outer Iter 108: norm_f = 53.5279, mu=168.223, |x|=0.485622, |J|=698.697\n",
      "      --- Outer Iter 109: norm_f = 53.5276, mu=352.55, |x|=0.485733, |J|=698.761\n",
      "      --- Outer Iter 110: norm_f = 53.5276, mu=656.701, |x|=0.48583, |J|=698.839\n",
      "      --- Outer Iter 111: norm_f = 53.5267, mu=659.085, |x|=0.485879, |J|=698.789\n",
      "      --- Outer Iter 112: norm_f = 53.5264, mu=638.62, |x|=0.48593, |J|=698.8\n",
      "      --- Outer Iter 113: norm_f = 53.5262, mu=338.352, |x|=0.485983, |J|=698.818\n",
      "      --- Outer Iter 114: norm_f = 53.5258, mu=112.784, |x|=0.48608, |J|=698.853\n",
      "      --- Outer Iter 115: norm_f = 53.5251, mu=110.506, |x|=0.486344, |J|=698.98\n",
      "      --- Outer Iter 116: norm_f = 53.5247, mu=866.184, |x|=0.486372, |J|=698.961\n",
      "      --- Outer Iter 117: norm_f = 53.5246, mu=288.728, |x|=0.486403, |J|=698.973\n",
      "      --- Outer Iter 118: norm_f = 53.5243, mu=96.2427, |x|=0.486496, |J|=699.007\n",
      "      --- Outer Iter 119: norm_f = 53.5235, mu=32.0809, |x|=0.486749, |J|=699.099\n",
      "      --- Outer Iter 120: norm_f = 53.5225, mu=28.5441, |x|=0.487328, |J|=699.349\n",
      "      --- Outer Iter 121: norm_f = 53.5223, mu=320.257, |x|=0.487374, |J|=699.406\n",
      "      --- Outer Iter 122: norm_f = 53.522, mu=333.271, |x|=0.487416, |J|=699.388\n",
      "      --- Outer Iter 123: norm_f = 53.5219, mu=334.372, |x|=0.487459, |J|=699.398\n",
      "      --- Outer Iter 124: norm_f = 53.5218, mu=331.224, |x|=0.487502, |J|=699.413\n",
      "      --- Outer Iter 125: norm_f = 53.5217, mu=267.893, |x|=0.487545, |J|=699.431\n",
      "      --- Outer Iter 126: norm_f = 53.5216, mu=145.435, |x|=0.487597, |J|=699.453\n",
      "      --- Outer Iter 127: norm_f = 53.5215, mu=108.384, |x|=0.487688, |J|=699.494\n",
      "      --- Outer Iter 128: norm_f = 53.5215, mu=155.995, |x|=0.487798, |J|=699.571\n",
      "      --- Outer Iter 129: norm_f = 53.5213, mu=314.046, |x|=0.487833, |J|=699.558\n",
      "      --- Outer Iter 130: norm_f = 53.5212, mu=309.908, |x|=0.487868, |J|=699.571\n",
      "      --- Outer Iter 131: norm_f = 53.5212, mu=195.298, |x|=0.487904, |J|=699.586\n",
      "      --- Outer Iter 132: norm_f = 53.5211, mu=65.0995, |x|=0.487959, |J|=699.61\n",
      "      --- Outer Iter 133: norm_f = 53.521, mu=57.3311, |x|=0.488111, |J|=699.685\n",
      "      --- Outer Iter 134: norm_f = 53.5209, mu=433.876, |x|=0.48813, |J|=699.687\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 53.5209 (92 data params - 31 model params = expected mean of 61; p-value = 0.740834)\n",
      "    Completed in 7.7s\n",
      "    2*Delta(log(L)) = 53.7555\n",
      "    Iteration 1 took 7.8s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 2 of 5  168 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (168 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 60 params (taken as 1 param groups of ~60 params).\n",
      "      --- Outer Iter 0: norm_f = 162.906, mu=1, |x|=0.48813, |J|=970.468\n",
      "      --- Outer Iter 1: norm_f = 161.307, mu=207.68, |x|=0.516943, |J|=918.907\n",
      "      --- Outer Iter 2: norm_f = 122.594, mu=69.2266, |x|=0.494036, |J|=943.901\n",
      "      --- Outer Iter 3: norm_f = 122.418, mu=32.1621, |x|=0.492689, |J|=945.203\n",
      "      --- Outer Iter 4: norm_f = 122.395, mu=14.2379, |x|=0.492364, |J|=945.298\n",
      "      --- Outer Iter 5: norm_f = 122.395, mu=186.08, |x|=0.492244, |J|=945.32\n",
      "      --- Outer Iter 6: norm_f = 122.394, mu=287.164, |x|=0.492209, |J|=945.271\n",
      "      --- Outer Iter 7: norm_f = 122.394, mu=301.027, |x|=0.49218, |J|=945.199\n",
      "      --- Outer Iter 8: norm_f = 122.394, mu=325.331, |x|=0.49215, |J|=945.159\n",
      "      --- Outer Iter 9: norm_f = 122.394, mu=328.324, |x|=0.492123, |J|=945.124\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 122.394 (168 data params - 31 model params = expected mean of 137; p-value = 0.809264)\n",
      "    Completed in 0.8s\n",
      "    2*Delta(log(L)) = 122.797\n",
      "    Iteration 2 took 0.8s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 3 of 5  285 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (285 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 60 params (taken as 1 param groups of ~60 params).\n",
      "      --- Outer Iter 0: norm_f = 267.019, mu=1, |x|=0.492123, |J|=1285.34\n",
      "      --- Outer Iter 1: norm_f = 227.386, mu=62.7295, |x|=0.49783, |J|=1274.81\n",
      "      --- Outer Iter 2: norm_f = 225.976, mu=20.9098, |x|=0.494926, |J|=1281.44\n",
      "      --- Outer Iter 3: norm_f = 225.911, mu=13.0123, |x|=0.494828, |J|=1280.24\n",
      "      --- Outer Iter 4: norm_f = 225.908, mu=824.998, |x|=0.494782, |J|=1280.14\n",
      "      --- Outer Iter 5: norm_f = 225.908, mu=298.922, |x|=0.494752, |J|=1280.1\n",
      "      --- Outer Iter 6: norm_f = 225.907, mu=99.6408, |x|=0.494686, |J|=1279.99\n",
      "      --- Outer Iter 7: norm_f = 225.905, mu=70.4327, |x|=0.494532, |J|=1279.72\n",
      "      --- Outer Iter 8: norm_f = 225.905, mu=559.788, |x|=0.494499, |J|=1279.7\n",
      "      --- Outer Iter 9: norm_f = 225.904, mu=291.794, |x|=0.494472, |J|=1279.66\n",
      "      --- Outer Iter 10: norm_f = 225.904, mu=97.2648, |x|=0.494425, |J|=1279.6\n",
      "      --- Outer Iter 11: norm_f = 225.903, mu=60.6153, |x|=0.494311, |J|=1279.44\n",
      "      --- Outer Iter 12: norm_f = 225.903, mu=453.863, |x|=0.494286, |J|=1279.42\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 225.903 (285 data params - 31 model params = expected mean of 254; p-value = 0.89723)\n",
      "    Completed in 1.4s\n",
      "    2*Delta(log(L)) = 226.21\n",
      "    Iteration 3 took 1.5s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 4 of 5  448 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (448 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 60 params (taken as 1 param groups of ~60 params).\n",
      "      --- Outer Iter 0: norm_f = 443.508, mu=1, |x|=0.494286, |J|=1698.76\n",
      "      --- Outer Iter 1: norm_f = 417.246, mu=91.8043, |x|=0.496465, |J|=1683.42\n",
      "      --- Outer Iter 2: norm_f = 416.652, mu=30.6014, |x|=0.494887, |J|=1687.9\n",
      "      --- Outer Iter 3: norm_f = 416.642, mu=30.9667, |x|=0.494824, |J|=1687.86\n",
      "      --- Outer Iter 4: norm_f = 416.637, mu=1713.63, |x|=0.494777, |J|=1687.76\n",
      "      --- Outer Iter 5: norm_f = 416.636, mu=1544.59, |x|=0.494747, |J|=1687.69\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 416.636 (448 data params - 31 model params = expected mean of 417; p-value = 0.495813)\n",
      "    Completed in 1.1s\n",
      "    2*Delta(log(L)) = 417.139\n",
      "    Iteration 4 took 1.2s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 5 of 5  616 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "      bulk_evaltree: created initial tree (616 strs) in 0s\n",
      "      bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "      Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "       groups of ~1 procs each, to distribute over 60 params (taken as 1 param groups of ~60 params).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      --- Outer Iter 0: norm_f = 591.026, mu=1, |x|=0.494747, |J|=2069.49\n",
      "      --- Outer Iter 1: norm_f = 569.98, mu=154.163, |x|=0.495192, |J|=2058.81\n",
      "      --- Outer Iter 2: norm_f = 569.902, mu=128.153, |x|=0.494479, |J|=2060.69\n",
      "      --- Outer Iter 3: norm_f = 569.886, mu=128.161, |x|=0.494422, |J|=2060.4\n",
      "      --- Outer Iter 4: norm_f = 569.882, mu=1024.68, |x|=0.494355, |J|=2060.34\n",
      "      --- Outer Iter 5: norm_f = 569.881, mu=806.892, |x|=0.494299, |J|=2060.27\n",
      "      --- Outer Iter 6: norm_f = 569.881, mu=268.964, |x|=0.494234, |J|=2060.17\n",
      "      --- Outer Iter 7: norm_f = 569.879, mu=106.881, |x|=0.494062, |J|=2059.92\n",
      "      --- Outer Iter 8: norm_f = 569.878, mu=218.614, |x|=0.493879, |J|=2059.7\n",
      "      --- Outer Iter 9: norm_f = 569.877, mu=591.508, |x|=0.493808, |J|=2059.62\n",
      "      --- Outer Iter 10: norm_f = 569.876, mu=604.309, |x|=0.493753, |J|=2059.53\n",
      "      --- Outer Iter 11: norm_f = 569.875, mu=604.344, |x|=0.493697, |J|=2059.46\n",
      "      --- Outer Iter 12: norm_f = 569.875, mu=584.596, |x|=0.493643, |J|=2059.38\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "    Sum of Chi^2 = 569.875 (616 data params - 31 model params = expected mean of 585; p-value = 0.665135)\n",
      "    Completed in 2.4s\n",
      "    2*Delta(log(L)) = 570.503\n",
      "    Iteration 5 took 2.6s\n",
      "    \n",
      "    Switching to ML objective (last iteration)\n",
      "    --- MLGST ---\n",
      "      --- Outer Iter 0: norm_f = 285.251, mu=1, |x|=0.493643, |J|=1455.85\n",
      "      --- Outer Iter 1: norm_f = 285.235, mu=76.2742, |x|=0.493252, |J|=1456.5\n",
      "      --- Outer Iter 2: norm_f = 285.234, mu=611.067, |x|=0.493203, |J|=1456.45\n",
      "      --- Outer Iter 3: norm_f = 285.234, mu=576.742, |x|=0.493158, |J|=1456.41\n",
      "      --- Outer Iter 4: norm_f = 285.234, mu=296.517, |x|=0.493111, |J|=1456.37\n",
      "      --- Outer Iter 5: norm_f = 285.233, mu=116.541, |x|=0.493025, |J|=1456.29\n",
      "      --- Outer Iter 6: norm_f = 285.233, mu=116.47, |x|=0.492825, |J|=1456.1\n",
      "      --- Outer Iter 7: norm_f = 285.232, mu=906.821, |x|=0.492799, |J|=1456.09\n",
      "      Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 1e-06\n",
      "      Maximum log(L) = 285.232 below upper bound of -1.02308e+06\n",
      "        2*Delta(log(L)) = 570.465 (616 data params - 31 model params = expected mean of 585; p-value = 0.658726)\n",
      "      Completed in 1.3s\n",
      "    2*Delta(log(L)) = 570.465\n",
      "    Final MLGST took 1.4s\n",
      "    \n",
      "  Iterative MLGST Total Time: 15.3s\n",
      "      -- Performing 'stdgaugeopt' gauge optimization on CPTP estimate --\n",
      "      -- Performing 'Spam 0.001' gauge optimization on CPTP estimate --\n",
      "      -- Performing 'Spam 0.001+v' gauge optimization on CPTP estimate --\n",
      "-- Std Practice:  Iter 3 of 3  (Target) --: \n",
      "      -- Performing 'stdgaugeopt' gauge optimization on Target estimate --\n",
      "      -- Performing 'Spam 0.001' gauge optimization on Target estimate --\n",
      "      -- Performing 'Spam 0.001+v' gauge optimization on Target estimate --\n",
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n",
      "*** Report Generation Complete!  Total time 91.5904s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x13a5989b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_std = pygsti.do_stdpractice_gst(ds, target_model, prep_fiducials, meas_fiducials, germs,\n",
    "                                        maxLengths, verbosity=4, modes=\"TP,CPTP,Target\",\n",
    "                                        gaugeOptSuite=('stdgaugeopt','toggleValidSpam'))\n",
    "\n",
    "# Generate a report with \"TP\", \"CPTP\", and \"Target\" estimates\n",
    "pygsti.report.create_standard_report(results_std, \"../tutorial_files/exampleStdReport\", \n",
    "                                     title=\"Post StdPractice Report\", auto_open=True,\n",
    "                                     verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports with confidence regions\n",
    "To display confidence intervals for reported quantities, you must do two things:\n",
    "\n",
    "1. you must specify the `confidenceLevel` argument to `create_standard_report`.\n",
    "2. the estimate(s) being reported must have a valid confidence-region-factory.\n",
    "\n",
    "Constructing a factory often means computing a Hessian, which can be time consuming, and so this is *not* done automatically.  Here we demonstrate how to construct a valid factory for the \"Spam 0.001\" gauge-optimization of the \"CPTP\" estimate by computing and then projecting the Hessian of the likelihood function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "--- Hessian Projector Optimization from separate SPAM and Gate weighting ---\n",
      "  Resulting intrinsic errors: 0.0104069 (gates), 0.00404055 (spam)\n",
      "  Resulting sqrt(mean(operationCIs**2)): 0.013539\n",
      "  Resulting sqrt(mean(spamCIs**2)): 0.00917909\n",
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Label{[]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a476f37ffe69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m pygsti.report.create_standard_report(results_std, \"../tutorial_files/exampleStdReport2\", \n\u001b[1;32m      7\u001b[0m                                      \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Post StdPractice Report (w/CIs on CPTP)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                      confidenceLevel=95, auto_open=True, verbosity=1)\n\u001b[0m",
      "\u001b[0;32m~/pyGSTi/pygsti/report/factory.py\u001b[0m in \u001b[0;36mcreate_standard_report\u001b[0;34m(results, filename, title, confidenceLevel, comm, ws, auto_open, link_to, brevity, advancedOptions, verbosity)\u001b[0m\n\u001b[1;32m    908\u001b[0m     addqty(4, 'bestGatesetGatesBoxTable', ws.GatesTable, switchBd.gsTargetAndFinal,\n\u001b[1;32m    909\u001b[0m            ['Target', 'Estimated'], \"boxes\", cri(1))\n\u001b[0;32m--> 910\u001b[0;31m     \u001b[0maddqty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bestGatesetChoiEvalTable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChoiTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsFinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"boxplot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"barplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m     \u001b[0maddqty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bestGatesetDecompTable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGateDecompTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsFinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsTgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     addqty(4, 'bestGatesetEvalTable', ws.GateEigenvalueTable, gsGIRep, gsTgt, criGIRep(1),\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/factory.py\u001b[0m in \u001b[0;36maddqty\u001b[0;34m(b, name, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbrevity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_timed_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatStr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{:45}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprinter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mqtys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0mqtys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mfactoryfn\u001b[0;34m(models, titles, confidenceRegionInfo, display)\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/workspacetables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ws, models, titles, confidenceRegionInfo, display)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \"\"\"\n\u001b[1;32m    445\u001b[0m         super(ChoiTable, self).__init__(ws, self._create, models, titles,\n\u001b[0;32m--> 446\u001b[0;31m                                         confidenceRegionInfo, display)\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidenceRegionInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/workspace.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ws, fn, *args)\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitchboards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbSwitchIndices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitchpos_map\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitchedCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtablefn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/workspace.py\u001b[0m in \u001b[0;36mswitchedCompute\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NA\"\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmartCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margVals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstoredKeys\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'INEFFECTIVE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/objects/smartcache.py\u001b[0m in \u001b[0;36mcached_compute\u001b[0;34m(self, fn, argVals, kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypesigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypesig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0m_timed_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margVals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"_filledarrays\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspecial_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                         self.outargs[key] = tuple((argVals[i] if isinstance(i, int) else kwargs[i]\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/workspacetables.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(self, models, titles, confidenceRegionInfo, display)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mchoiMxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'eigenvalues'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'barplot'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_ev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_reportables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChoi_evals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidenceRegionInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopLabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/workspacetables.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mchoiMxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'eigenvalues'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'barplot'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_ev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_reportables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChoi_evals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidenceRegionInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopLabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/report/reportables.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(modelFn, cri, verbosity)\u001b[0m\n\u001b[1;32m     85\u001b[0m         df, f0 = cri.get_fn_confidence_interval(\n\u001b[1;32m     86\u001b[0m             \u001b[0mmodelFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnFnVal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             verbosity=verbosity)\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_reportable_qty_or_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmEBs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/objects/confidenceregionfactory.py\u001b[0m in \u001b[0;36mget_fn_confidence_interval\u001b[0;34m(self, fnObj, eps, returnFnVal, verbosity)\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0;31m# copy objects because we add eps to them below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdependency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodelObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prep\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodelObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"povm\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodelObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpovms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyGSTi/pygsti/objects/labeldicts.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m#    self.parent._clean_paramvec()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedMemberDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_auto_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Label{[]}"
     ]
    }
   ],
   "source": [
    "#Construct and initialize a \"confidence region factory\" for the CPTP estimate\n",
    "crfact = results_std.estimates[\"CPTP\"].add_confidence_region_factory('Spam 0.001', 'final')\n",
    "crfact.compute_hessian(comm=None) #we could use more processors\n",
    "crfact.project_hessian('intrinsic error')\n",
    "\n",
    "pygsti.report.create_standard_report(results_std, \"../tutorial_files/exampleStdReport2\", \n",
    "                                     title=\"Post StdPractice Report (w/CIs on CPTP)\",\n",
    "                                     confidenceLevel=95, auto_open=True, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports with multiple *different* data sets\n",
    "We've already seen above that `create_standard_report` can be given a dictionary of `Results` objects instead of a single one.  This allows the creation of reports containing estimates for different `DataSet`s (each `Results` object only holds estimates for a single `DataSet`).  Furthermore, when the data sets have the same operation sequences, they will be compared within a tab of the HTML report.\n",
    "\n",
    "Below, we generate a new data set with the same sequences as the one loaded at the beginning of this tutorial, proceed to run standard-practice GST on that dataset, and create a report of the results along with those of the original dataset.  Look at the **\"Data Comparison\" tab** within the gauge-invariant error metrics category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Circuit Creation ---\n",
      "   616 sequences created\n",
      "-- Std Practice:  Iter 1 of 3  (TP) --: \n",
      "  --- Iterative MLGST: Iter 1 of 5  92 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 50.2567 (92 data params - 31 model params = expected mean of 61; p-value = 0.835246)\n",
      "    Completed in 0.5s\n",
      "    2*Delta(log(L)) = 50.4026\n",
      "    Iteration 1 took 0.5s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 2 of 5  168 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 112.85 (168 data params - 31 model params = expected mean of 137; p-value = 0.934965)\n",
      "    Completed in 0.4s\n",
      "    2*Delta(log(L)) = 112.943\n",
      "    Iteration 2 took 0.4s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 3 of 5  285 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 222.419 (285 data params - 31 model params = expected mean of 254; p-value = 0.924211)\n",
      "    Completed in 0.4s\n",
      "    2*Delta(log(L)) = 222.551\n",
      "    Iteration 3 took 0.5s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 4 of 5  448 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 405.964 (448 data params - 31 model params = expected mean of 417; p-value = 0.641484)\n",
      "    Completed in 0.7s\n",
      "    2*Delta(log(L)) = 406.046\n",
      "    Iteration 4 took 0.8s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 5 of 5  616 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 607.118 (616 data params - 31 model params = expected mean of 585; p-value = 0.255239)\n",
      "    Completed in 0.9s\n",
      "    2*Delta(log(L)) = 607.19\n",
      "    Iteration 5 took 1.1s\n",
      "    \n",
      "    Switching to ML objective (last iteration)\n",
      "    --- MLGST ---\n",
      "      Maximum log(L) = 303.577 below upper bound of -1.02334e+06\n",
      "        2*Delta(log(L)) = 607.155 (616 data params - 31 model params = expected mean of 585; p-value = 0.254907)\n",
      "      Completed in 0.8s\n",
      "    2*Delta(log(L)) = 607.155\n",
      "    Final MLGST took 0.8s\n",
      "    \n",
      "  Iterative MLGST Total Time: 4.1s\n",
      "-- Std Practice:  Iter 2 of 3  (CPTP) --: \n",
      "  --- Iterative MLGST: Iter 1 of 5  92 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 50.2599 (92 data params - 31 model params = expected mean of 61; p-value = 0.835167)\n",
      "    Completed in 5.7s\n",
      "    2*Delta(log(L)) = 50.4032\n",
      "    Iteration 1 took 5.8s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 2 of 5  168 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 112.852 (168 data params - 31 model params = expected mean of 137; p-value = 0.934945)\n",
      "    Completed in 1.6s\n",
      "    2*Delta(log(L)) = 112.945\n",
      "    Iteration 2 took 1.6s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 3 of 5  285 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 222.42 (285 data params - 31 model params = expected mean of 254; p-value = 0.9242)\n",
      "    Completed in 1.5s\n",
      "    2*Delta(log(L)) = 222.552\n",
      "    Iteration 3 took 1.6s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 4 of 5  448 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 405.968 (448 data params - 31 model params = expected mean of 417; p-value = 0.64143)\n",
      "    Completed in 1.3s\n",
      "    2*Delta(log(L)) = 406.051\n",
      "    Iteration 4 took 1.5s\n",
      "    \n",
      "  --- Iterative MLGST: Iter 5 of 5  616 operation sequences ---: \n",
      "    --- Minimum Chi^2 GST ---\n",
      "    Sum of Chi^2 = 607.12 (616 data params - 31 model params = expected mean of 585; p-value = 0.255224)\n",
      "    Completed in 1.6s\n",
      "    2*Delta(log(L)) = 607.194\n",
      "    Iteration 5 took 1.8s\n",
      "    \n",
      "    Switching to ML objective (last iteration)\n",
      "    --- MLGST ---\n",
      "      Maximum log(L) = 303.579 below upper bound of -1.02334e+06\n",
      "        2*Delta(log(L)) = 607.157 (616 data params - 31 model params = expected mean of 585; p-value = 0.254885)\n",
      "      Completed in 0.5s\n",
      "    2*Delta(log(L)) = 607.157\n",
      "    Final MLGST took 0.5s\n",
      "    \n",
      "  Iterative MLGST Total Time: 12.8s\n",
      "-- Std Practice:  Iter 3 of 3  (Target) --: \n",
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enielse/pyGSTi/pygsti/report/factory.py:1135: UserWarning:\n",
      "\n",
      "Not all data sets are comparable - no comparisions will be made.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Report Generation Complete!  Total time 212.754s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x14029d208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make another dataset & estimates\n",
    "depol_gateset = target_model.depolarize(op_noise=0.1)\n",
    "datagen_gateset = depol_gateset.rotate((0.05,0,0.03))\n",
    "\n",
    "#Compute the sequences needed to perform Long Sequence GST on \n",
    "# this Model with sequences up to lenth 512\n",
    "circuit_list = pygsti.construction.make_lsgst_experiment_list(\n",
    "    smq1Q_XYI.target_model(), smq1Q_XYI.prep_fiducials(), smq1Q_XYI.meas_fiducials(),\n",
    "    smq1Q_XYI.germs(), [1,2,4,8,16,32,64,128,256,512])\n",
    "ds2 = pygsti.construction.generate_fake_data(datagen_gateset, circuit_list, nSamples=1000,\n",
    "                                             sampleError='binomial', seed=2018)\n",
    "results_std2 = pygsti.do_stdpractice_gst(ds2, target_model, prep_fiducials, meas_fiducials, germs,\n",
    "                                     maxLengths, verbosity=3, modes=\"TP,CPTP,Target\",\n",
    "                                     gaugeOptSuite=('stdgaugeopt','toggleValidSpam'))\n",
    "\n",
    "pygsti.report.create_standard_report({'DS1': results_std, 'DS2': results_std2},\n",
    "                                    \"../tutorial_files/exampleMultiDataSetReport\", \n",
    "                                    title=\"Example Multi-Dataset Report\", \n",
    "                                    auto_open=True, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other cool `create_standard_report` options\n",
    "Finally, let us highlight a few of the additional arguments one can supply to `create_standard_report` that allows further control over what gets reported.\n",
    "\n",
    "- Setting the `link_to` argument to a tuple of `'pkl'`, `'tex'`, and/or `'pdf'` will create hyperlinks within the plots or below the tables of the HTML linking to Python pickle, LaTeX source, and PDF versions of the content, respectively.  The Python pickle files for tables contain pickled pandas `DataFrame` objects, wheras those of plots contain ordinary Python dictionaries of the data that is plotted.  Applies to HTML reports only.\n",
    "\n",
    "- Setting the `brevity` argument to an integer higher than $0$ (the default) will reduce the amount of information included in the report (for details on what is included for each value, see the doc string).  Using `brevity > 0` will reduce the time required to create, and later load, the report, as well as the output file/folder size.  This applies to both HTML and PDF reports.\n",
    "\n",
    "Below, we demonstrate both of these options in very brief (`brevity=4`) report with links to pickle and PDF files.  Note that to generate the PDF files you must have `pdflatex` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "Found standard clifford compilation from smq1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n",
      "*** Report Generation Complete!  Total time 92.8786s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x1597c14a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygsti.report.create_standard_report(results_std,\n",
    "                                    \"../tutorial_files/exampleBriefReport\", \n",
    "                                    title=\"Example Brief Report\", \n",
    "                                    auto_open=True, verbosity=1,\n",
    "                                    brevity=4, link_to=('pkl','pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Advanced Reports: `create_report_notebook`\n",
    "In addition to the standard HTML-page reports demonstrated above, pyGSTi is able to generate a Jupyter notebook containing the Python commands to create the figures and tables within a general report.  This is facilitated\n",
    "by `Workspace` objects, which are factories for figures and tables (see previous tutorials).  By calling `create_report_notebook`, all of the relevant `Workspace` initialization and calls are dumped to a new notebook file, which can be run (either fully or partially) by the user at their convenience.  Creating such \"report notebooks\" has the advantage that the user may insert Python code amidst the figure and table generation calls to inspect or modify what is display in a highly customizable fashion.  The chief disadvantages of report notebooks is that they require the user to 1) have a Jupyter server up and running and 2) to run the notebook before any figures are displayed.\n",
    "\n",
    "The line below demonstrates how to create a report notebook using `create_report_notebook`.  Note that the argument list is very similar to `create_general_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Notebook created as ../tutorial_files/exampleReport.ipynb\n"
     ]
    }
   ],
   "source": [
    "pygsti.report.create_report_notebook(results, \"../tutorial_files/exampleReport.ipynb\", \n",
    "                                     title=\"GST Example Report Notebook\", confidenceLevel=None,\n",
    "                                     auto_open=True, connected=False, verbosity=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-qubit reports\n",
    "The dimension of the density matrix space with with more than 2 qubits starts to become quite large, and Models for 3+ qubits rarely allow every element of the operation process matrices to vary independently.  As such, many of the figures generated by `create_standard_report` are both too unwieldy (displaying a $64 \\times 64$ grid of colored boxes for each operation) and not very helpful (you don't often care about what each element of an operation matrix is).  For this purpose, we are developing a report that doesn't just dump out and analyze operation matrices as a whole, but looks at a `Model`'s structure to determine how best to report quantities.  This \"n-qubit report\" is invoked using `pygsti.report.create_nqnoise_report`, and has similar arguments to `create_standard_report`.  It is, however <b style=\"color:red\">still under development</b>, and while you're welcome to try it out, it may crash or not work in other weird ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
